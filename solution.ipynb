{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving a Lunar Lander with differentiable Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "To install the required libraries run the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports from the standard genepro-multi library are done here. Any adjustments (e.g. different operators) should be made in the notebook. For example:\n",
    "\n",
    "```\n",
    "class SmoothOperator(Node):\n",
    "  def __init__(self):\n",
    "    super(SmoothOperator,self).__init__()\n",
    "    self.arity = 1\n",
    "    self.symb = \"SmoothOperator\"\n",
    "\n",
    "  def _get_args_repr(self, args):\n",
    "    return self._get_typical_repr(args,'before')\n",
    "\n",
    "  def get_output(self, X):\n",
    "    c_outs = self._get_child_outputs(X)\n",
    "    return np.smoothOperation(c_outs[0])\n",
    "\n",
    "  def get_output_pt(self, X):\n",
    "    c_outs = self._get_child_outputs_pt(X)\n",
    "    return torch.smoothOperation(c_outs[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch.optim as optim\n",
    "from matplotlib import animation\n",
    "from numpy import ndarray\n",
    "\n",
    "from genepro.evo import Evolution\n",
    "from genepro.multitree import Multitree\n",
    "from genepro.node_impl import *\n",
    "from genepro.node_impl import Constant\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Setup\n",
    "Here we first setup the Gymnasium environment. Please see https://gymnasium.farama.org/environments/box2d/lunar_lander/ for more information on the environment. \n",
    "\n",
    "Then a memory buffer is made. This is a buffer in which state transitions are stored. When the buffer reaches its maximum capacity old transitions are replaced by new ones.\n",
    "\n",
    "A frame buffer is initialised, used to later store animation frames of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Wind\n",
    "\n",
    "Wind can be added to the current environment setup as below:\n",
    "\n",
    "```bash\n",
    "env = gym.make(\"LunarLander-v3\", continuous=False,\n",
    "               enable_wind=True, wind_power=15.0, turbulence_power=1.5)\n",
    "```\n",
    "\n",
    "Selin: When we add wind as a variable, it makes sense to also edit our fitness function. We can define a new boolean parameter (say have_random_wind) and if it is set to true when the fitness function is called, we can re-define the environment with a random wind value at each episode. This would potentially make our GP algorithm more robust to randomness. A possible implementation:\n",
    "\n",
    "```bash\n",
    "if use_random_wind:\n",
    "    env = gym.make(\"LunarLander-v3\", continuous=False,\n",
    "                    enable_wind=True,\n",
    "                    wind_power=np.random.uniform(5.0, 20.0),\n",
    "                    turbulence_power=np.random.uniform(0.5, 2.0))\n",
    "```\n",
    "\n",
    "The above can be added within the loop that goes over the episodes (the outer for loop of the fitness function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new Atomic Functions\n",
    "\n",
    "These atomic functions will be added as internal nodes within the Evolution setup.\n",
    "\n",
    "We can add min & max operators. Or instead, we can add **Clamp(x, min, max)** operator. This could be interesting.\n",
    "\n",
    "We can add domain specific operators:\n",
    "- Maybe a function that calculates the angle of the lunarlander to the pad (angle_to_pad(x_pos, y_pos)?)\n",
    "\n",
    "#### Fitness Calculation\n",
    "\n",
    "For the final fitness calculation, we are taking the sum of the rewards across episodes. Instead of sum operation, can we do this fitness calculation in a more clever way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_normal_evolution = False\n",
    "perform_hyperparameter_testing = False\n",
    "perform_fitness_test = False\n",
    "perform_operator_test = False\n",
    "perform_multiobjective_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"next_state\", \"reward\"))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        self.memory += other.memory\n",
    "        return self\n",
    "\n",
    "    def __add__(self, other):\n",
    "        self.memory = self.memory + other.memory\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function\n",
    "\n",
    "Here you get to be creative. The default setup evaluates 5 episodes of 300 frames. Think of what action to pick and what fitness function to use. The Multi-tree takes an input of $n \\times d$ where $n$ is a batch of size 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selin's Notes\n",
    "\n",
    "**Fitness Function:** Fitness is defined as the cumulative reward of the landing.\n",
    "\n",
    "**Multitree:** Multitree contains 4 trees, one for each action of the Lunar lander. \n",
    "\n",
    "- `0`: do nothing\n",
    "- `1`: fire left orientation engine\n",
    "- `2`: fire main engine\n",
    "- `3`: fire right orientation engine\n",
    "\n",
    "Multitree is initialized under genepro/variation.py file, with the generate_random_multitree() method. This method is called in the genepro/evo.py file within the _initialize_population() internal method. \n",
    "\n",
    "**Understanding the Input Sample:** Input sample is an 8-dimensional vector: [x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact]\n",
    "\n",
    "e.g. [-2.5, -2.5, -10, -10, -6.28, -10, 0, 0]\n",
    "\n",
    "- index0 : x position of the lander\n",
    "- index1: y position of the lander\n",
    "- index2: velocity in the x direction\n",
    "- index3: velocity in the y direction\n",
    "- index4: angle of the lander\n",
    "- index5: angular velocity\n",
    "- index6: leg 1 in contact\n",
    "- index7: leg 2 in contact\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fitness_function_pt(reduction=\"sum\", has_wind=False):\n",
    "    \"\"\"\n",
    "    Generic fitness function factory\n",
    "    \"\"\"\n",
    "\n",
    "    def fitness_function(\n",
    "        multitree, num_episodes=5, episode_duration=300, render=False, ignore_done=False\n",
    "    ):\n",
    "        memory = ReplayMemory(10000)\n",
    "        episode_returns = []\n",
    "\n",
    "        for _ in range(num_episodes):\n",
    "            rewards = []\n",
    "            # define a new environment with or without wind\n",
    "            if has_wind:\n",
    "                env = gym.make(\n",
    "                    \"LunarLander-v3\",\n",
    "                    render_mode=\"rgb_array\",\n",
    "                    enable_wind=True,\n",
    "                    wind_power=np.random.uniform(\n",
    "                        0.0, 2.0\n",
    "                    ),  # TODO: Update the parameters for wind if necessary\n",
    "                    turbulence_power=np.random.uniform(0.0, 1.0),\n",
    "                )  # TODO: Update the parameters for turbulence if necessary\n",
    "            else:\n",
    "                env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "            observation = env.reset()\n",
    "            observation = observation[0]\n",
    "\n",
    "            for _ in range(episode_duration):\n",
    "                if render:\n",
    "                    frames.append(env.render())\n",
    "\n",
    "                input_sample = torch.from_numpy(\n",
    "                    observation.reshape((1, -1))\n",
    "                ).float()  # Input sample is a torch tensor\n",
    "\n",
    "                # what goes here? TODO\n",
    "                \"\"\"Below is Selin's possible definition of an action\"\"\"\n",
    "                output_scores = multitree.get_output_pt(\n",
    "                    input_sample\n",
    "                )  # A tensor of length 4, storing the scores of each action (after evaluating each tree)\n",
    "                action = torch.argmax(\n",
    "                    output_scores, dim=1\n",
    "                )  # Select the action with the highest score\n",
    "                observation, reward, terminated, truncated, info = env.step(\n",
    "                    action.item()\n",
    "                )\n",
    "                rewards.append(reward)\n",
    "                output_sample = torch.from_numpy(observation.reshape((1, -1))).float()\n",
    "                memory.push(\n",
    "                    input_sample,\n",
    "                    torch.tensor([[action.item()]]),\n",
    "                    output_sample,\n",
    "                    torch.tensor([reward]),\n",
    "                )\n",
    "                if (terminated or truncated) and not ignore_done:\n",
    "                    break\n",
    "\n",
    "            # Store the sum of rewards for this episode\n",
    "            episode_returns.append(np.sum(rewards))\n",
    "\n",
    "        # Define the reward types here\n",
    "        # TODO: Add more reward types!\n",
    "        if reduction == \"sum\":\n",
    "            fitness = np.sum(episode_returns)\n",
    "        elif reduction == \"avg\":\n",
    "            fitness = np.sum(episode_returns) / num_episodes\n",
    "        elif reduction == \"min\":\n",
    "            fitness = np.min(episode_returns)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown reduction method: {reduction}\")\n",
    "\n",
    "        return fitness, memory\n",
    "\n",
    "    return fitness_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Setup\n",
    "Here the leaf and internal nodes are defined. Think about the odds of sampling a constant in this default configurations. Also think about any operators that could be useful and add them here. \n",
    "\n",
    "Adjust the population size (multiple of 8 if you want to use the standard tournament selection), max generations and max tree size to taste. Be aware that each of these settings can increase the runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selin's ideas about the things they wanted us to consider in the evolution setup (possible areas for improvement)\n",
    "\n",
    "In the below code, it says **Think about the probability of sampling a coefficient (which is basically a constant).** Currently, in the below code, we have 8 features and we are adding all of them as leaf nodes. \n",
    "\n",
    "However, we are only adding 1 constant as a leaf node. So this would give us a 1/9 chance of sampling a coefficient. This is a very small probability. Hence, **a possible area of improvement** might be to consider adding more constants (e.g. 4 or 5 constants) to our leaf nodes set and see how our GP performs. I think having constant is **important** because they allow the model to shift or scale features (e.g. x_4 + 1.5).\n",
    "\n",
    "**Having more operators:** Currently, we only have basic arithmetic operators. We can add the following non-linear operators:\n",
    "- log\n",
    "- sqrt\n",
    "- sin, cos\n",
    "- max, min\n",
    "- exp\n",
    "- square, cube, ...\n",
    "\n",
    "**Adjusting the parameters of the Evolution() method** called below. We can design an experiment to find the best combination of parameter values for population size, max generations, and max tree size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [\n",
    "    Constant()\n",
    "]  # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [Plus(), Minus(), Times(), Div()]  # Add your own operators here\n",
    "\n",
    "fitness_function_pt = make_fitness_function_pt(\n",
    "    reduction=\"sum\"\n",
    ")  # Baseline fitness function\n",
    "\n",
    "evo = Evolution(\n",
    "    fitness_function_pt,\n",
    "    internal_nodes,\n",
    "    leaf_nodes,\n",
    "    4,\n",
    "    pop_size=16,\n",
    "    max_gens=10,\n",
    "    max_tree_size=31,\n",
    "    n_jobs=8,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolve\n",
    "Running this cell will use all the settings above as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_normal_evolution:\n",
    "    best_fitnesses_across_gens = evo.evolve(is_multiobjective=False)\n",
    "    print(best_fitnesses_across_gens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_score(tree, has_wind=False):\n",
    "    rewards = []\n",
    "\n",
    "    for i in range(10):\n",
    "        # define a new environment with or without wind\n",
    "        if has_wind:\n",
    "            env = gym.make(\n",
    "                \"LunarLander-v3\",\n",
    "                render_mode=\"rgb_array\",\n",
    "                enable_wind=True,\n",
    "                wind_power=np.random.uniform(\n",
    "                    0.0, 2.0\n",
    "                ),  # TODO: Update the parameters for wind if necessary\n",
    "                turbulence_power=np.random.uniform(0.0, 1.0),\n",
    "            )  # TODO: Update the parameters for turbulence if necessary\n",
    "        else:\n",
    "            env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "        observation = env.reset(seed=i)\n",
    "        observation = observation[0]\n",
    "\n",
    "        for _ in range(500):\n",
    "            # build up the input sample for GP\n",
    "            input_sample = torch.from_numpy(observation.reshape((1, -1))).float()\n",
    "\n",
    "            # TODO: Again, define the action\n",
    "            \"\"\"Selin's idea of an action is added below\"\"\"\n",
    "            # get output (squeezing because it is encapsulated in an array)\n",
    "            output = tree.get_output_pt(input_sample)\n",
    "            action = torch.argmax(\n",
    "                output, dim=1\n",
    "            )  # Select the action with the highest score\n",
    "\n",
    "            observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "            rewards.append(reward)\n",
    "            output_sample = torch.from_numpy(observation.reshape((1, -1))).float()\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "    fitness = np.sum(rewards)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "\n",
    "if perform_normal_evolution:\n",
    "    best = evo.best_of_gens[-1]\n",
    "\n",
    "    print(best.get_readable_repr())\n",
    "    print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Experimentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_to_csv(\n",
    "    internal_nodes,\n",
    "    leaf_nodes,\n",
    "    pop_size,\n",
    "    max_gens,\n",
    "    max_tree_size,\n",
    "    crossover_rate,\n",
    "    mutation_rate,\n",
    "    coeff_opt_rate,\n",
    "    tournament_size,\n",
    "    best_training,\n",
    "    best_test,\n",
    "    average_fitness,\n",
    "    time_elapsed,\n",
    "    num_evals,\n",
    "    filename=\"experiment_results_cr=0.500.csv\",\n",
    "):\n",
    "    # Flatten node types to strings for logging\n",
    "    internal_str = \",\".join(type(node).__name__ for node in internal_nodes)\n",
    "    leaf_str = \",\".join(type(node).__name__ for node in leaf_nodes)\n",
    "\n",
    "    # Build a dictionary of all results/settings\n",
    "    row = {\n",
    "        \"internal_nodes\": internal_str,\n",
    "        \"leaf_nodes\": leaf_str,\n",
    "        \"pop_size\": pop_size,\n",
    "        \"max_gens\": max_gens,\n",
    "        \"max_tree_size\": max_tree_size,\n",
    "        \"crossover_rate\": crossover_rate,\n",
    "        \"mutation_rate\": mutation_rate,\n",
    "        \"coeff_opt_rate\": coeff_opt_rate,\n",
    "        \"tournament_size\": tournament_size,\n",
    "        \"best_training\": best_training,\n",
    "        \"best_test\": best_test,\n",
    "        \"average_fitness\": average_fitness,\n",
    "        \"time_elapsed\": time_elapsed,\n",
    "        \"num_evals\": num_evals,\n",
    "    }\n",
    "\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=list(row.keys()))\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Experimentation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genepro.evo import (\n",
    "    subtree_crossover,\n",
    "    subtree_mutation,\n",
    "    coeff_mutation,\n",
    "    tournament_selection,\n",
    ")\n",
    "\n",
    "# Hyperparameters in the baseline implementation which will be kept as is\n",
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [\n",
    "    Constant()\n",
    "]  # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [Plus(), Minus(), Times(), Div()]  # Add your own operators here\n",
    "\n",
    "\n",
    "def main_experimentation_loop(\n",
    "    fitness_function_version,\n",
    "    internal_nodes,\n",
    "    leaf_nodes,\n",
    "    pop_size=64,\n",
    "    max_gens=30,\n",
    "    max_tree_size=31,\n",
    "    crossover_rate=0.875,\n",
    "    mutation_rate=0.025,\n",
    "    coeff_opt_rate=0.1,\n",
    "    tournament_size=8,\n",
    "    is_multiobjective=False,\n",
    "):\n",
    "    # Define the best-performing hyperparameters\n",
    "    crossovers = [{\"fun\": subtree_crossover, \"rate\": crossover_rate}]\n",
    "    mutations = [{\"fun\": subtree_mutation, \"rate\": mutation_rate}]\n",
    "    coeff_opts = [{\"fun\": coeff_mutation, \"rate\": coeff_opt_rate}]\n",
    "    selection = {\n",
    "        \"fun\": tournament_selection,\n",
    "        \"kwargs\": {\"tournament_size\": tournament_size},\n",
    "    }\n",
    "\n",
    "    # Initialize an evolution setup with the correct fitness function\n",
    "    evo = Evolution(\n",
    "        fitness_function_version,\n",
    "        internal_nodes,\n",
    "        leaf_nodes,\n",
    "        n_trees=4,  # Number of trees in multitree is fixed to 4\n",
    "        # resource settings\n",
    "        pop_size=pop_size,\n",
    "        max_gens=max_gens,\n",
    "        max_tree_size=max_tree_size,\n",
    "        # hyperparameter settings\n",
    "        crossovers=crossovers,\n",
    "        mutations=mutations,\n",
    "        coeff_opts=coeff_opts,\n",
    "        selection=selection,\n",
    "        n_jobs=8,  # Number of jobs is fixed to 8 (used for parallel computing)\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Run the training loop for this evolution setup and get the fitnesses of the best individuals across generations\n",
    "    best_fitnesses_training, average_fitness, time_elapsed, num_evals = evo.evolve(\n",
    "        is_multiobjective=is_multiobjective\n",
    "    )\n",
    "\n",
    "    # Now, run the testing loop for this evolution setup and get the fitnesses of the best individuals across generations\n",
    "    # Extract best-of-generation trees\n",
    "    best_individuals = evo.best_of_gens\n",
    "\n",
    "    # Collect test scores for each best individual across generations\n",
    "    best_fitnesses_test = [get_test_score(ind) for ind in best_individuals]\n",
    "\n",
    "    # Collect the average test score across the final population\n",
    "    final_population = evo.population\n",
    "    final_population_test_scores = [get_test_score(ind) for ind in final_population]\n",
    "    average_fitness_test = np.mean(final_population_test_scores)\n",
    "\n",
    "    return (\n",
    "        best_fitnesses_training,\n",
    "        best_fitnesses_test,\n",
    "        average_fitness,\n",
    "        average_fitness_test,\n",
    "        time_elapsed,\n",
    "        num_evals,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Baseline Model: Hyperparameter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE TEST. Hyperparameter Testing\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def hyperparameter_testing():\n",
    "    crossover_rates = [0.5, 0.625, 0.75, 0.875, 1.0]\n",
    "    mutation_rates = [0.01, 0.025, 0.05, 0.075, 0.125]\n",
    "    coeff_opt_rates = [0.01, 0.025, 0.05, 0.075, 0.125, 0.25]\n",
    "    tournament_sizes = [2, 4, 8, 16]\n",
    "\n",
    "    total_runs = (\n",
    "        len(crossover_rates)\n",
    "        * len(mutation_rates)\n",
    "        * len(coeff_opt_rates)\n",
    "        * len(tournament_sizes)\n",
    "    )\n",
    "    run_idx = 1\n",
    "\n",
    "    baseline_fitness_function = make_fitness_function_pt(\n",
    "        reduction=\"sum\"\n",
    "    )  # Test against the baseline fitness function: sum of rewards\n",
    "\n",
    "    for cr, mr, cor, ts in product(\n",
    "        crossover_rates, mutation_rates, coeff_opt_rates, tournament_sizes\n",
    "    ):\n",
    "        print(\n",
    "            f\"\\n=== Run {run_idx}/{total_runs} | CR={cr} MR={mr} CoeffR={cor} TS={ts} ===\"\n",
    "        )\n",
    "        run_idx += 1\n",
    "\n",
    "        try:\n",
    "            (\n",
    "                best_training,\n",
    "                best_test,\n",
    "                average_fitness,\n",
    "                average_fitness_test,\n",
    "                time_elapsed,\n",
    "                num_evals,\n",
    "            ) = main_experimentation_loop(\n",
    "                fitness_function_version=baseline_fitness_function,\n",
    "                internal_nodes=internal_nodes,\n",
    "                leaf_nodes=leaf_nodes,\n",
    "                crossover_rate=cr,\n",
    "                mutation_rate=mr,\n",
    "                coeff_opt_rate=cor,\n",
    "                tournament_size=ts,\n",
    "            )\n",
    "\n",
    "            write_results_to_csv(\n",
    "                internal_nodes=internal_nodes,\n",
    "                leaf_nodes=leaf_nodes,\n",
    "                pop_size=64,\n",
    "                max_gens=30,\n",
    "                max_tree_size=31,\n",
    "                crossover_rate=cr,\n",
    "                mutation_rate=mr,\n",
    "                coeff_opt_rate=cor,\n",
    "                tournament_size=ts,\n",
    "                best_training=best_training,\n",
    "                best_test=best_test,\n",
    "                average_fitness=average_fitness,\n",
    "                time_elapsed=time_elapsed,\n",
    "                num_evals=num_evals,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error in configuration CR={cr}, MR={mr}, CoeffR={cor}, TS={ts}: {e}\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "\n",
    "if perform_hyperparameter_testing:\n",
    "    hyperparameter_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1. Improving the Fitness Function\n",
    "\n",
    "Configuring the fitness function:\n",
    "- TEST 1.1 Single objective: Experiment with different quality metrics for fitness\n",
    "- TEST 1.2 Multi-objective: Include diversity as a second metric\n",
    "\n",
    "Required additional arguments for fitness function: has_wind=False, reward_type='sum', is_multiobjective=False where reward_types = ['sum', 'min', 'weighted_sum']\n",
    "\n",
    "Wind Test: Adding wind as a variable, and also adding a random wind value at each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST TYPE 1. Improving the Fitness Function\n",
    "\"\"\"\n",
    "Configuring the fitness function\n",
    "TEST 1.1 Single objective: Experiment with different quality metrics for fitness\n",
    "TEST 1.2 Multi-objective: Include diversity as a second metric\n",
    "\n",
    "Required additional arguments for fitness function: has_wind=False, reward_type='sum', is_multiobjective=False\n",
    "where reward_types = ['sum', 'min', 'weighted_sum']\n",
    "\n",
    "Wind Test\n",
    "Adding wind as a variable, and also adding a random wind value at each episode\n",
    "\"\"\"\n",
    "\n",
    "def write_results_to_csv_fitness_improvement(\n",
    "    internal_nodes,\n",
    "    leaf_nodes,\n",
    "    has_wind,\n",
    "    reward_type,\n",
    "    pop_size,\n",
    "    max_gens,\n",
    "    best_training,\n",
    "    best_test,\n",
    "    average_fitness,\n",
    "    time_elapsed,\n",
    "    num_evals,\n",
    "):\n",
    "    # Flatten node types to strings for logging\n",
    "    internal_str = \",\".join(type(node).__name__ for node in internal_nodes)\n",
    "    leaf_str = \",\".join(type(node).__name__ for node in leaf_nodes)\n",
    "\n",
    "    # Build a dictionary of all results/settings\n",
    "    row = {\n",
    "        \"internal_nodes\": internal_str,\n",
    "        \"leaf_nodes\": leaf_str,\n",
    "        \"has_wind\": has_wind,\n",
    "        \"reward_type\": reward_type,\n",
    "        \"pop_size\": pop_size,\n",
    "        \"max_gens\": max_gens,\n",
    "        \"best_training\": best_training,\n",
    "        \"best_test\": best_test,\n",
    "        \"average_fitness\": average_fitness,\n",
    "        \"time_elapsed\": time_elapsed,\n",
    "        \"num_evals\": num_evals,\n",
    "    }\n",
    "\n",
    "    name = \"fitness_comp_improvement.csv\"\n",
    "    if has_wind:\n",
    "        name = \"fitness_comp_improvement_with_wind.csv\"\n",
    "\n",
    "    os.makedirs(\"improvement_results\", exist_ok=True)\n",
    "    filename = os.path.join(\"improvement_results\", name)\n",
    "\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=list(row.keys()))\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "def fitness_function_reward_types_exp(max_gens=30, has_wind=False):\n",
    "    reward_types = [\"avg\", \"min\"]  # Use average instead of sum for comparison purposes\n",
    "\n",
    "    for _ in range(\n",
    "        3\n",
    "    ):  # Run the experiment for 3 times for each reward type (to account for randomness)\n",
    "        for reward_type in reward_types:\n",
    "            fitness_function_version = make_fitness_function_pt(\n",
    "                reduction=reward_type, has_wind=has_wind\n",
    "            )\n",
    "            print(f\"\\nRunning experiment for reward type: {reward_type}\")\n",
    "            (\n",
    "                best_training,\n",
    "                best_test,\n",
    "                average_fitness,\n",
    "                average_fitness_test,\n",
    "                time_elapsed,\n",
    "                num_evals,\n",
    "            ) = main_experimentation_loop(\n",
    "                fitness_function_version,\n",
    "                internal_nodes,\n",
    "                leaf_nodes,\n",
    "                pop_size=64,\n",
    "                max_gens=max_gens,\n",
    "                max_tree_size=31,\n",
    "            )\n",
    "            print(\n",
    "                f\"Best training fitness: {best_training}, Best test fitness: {best_test}, Average fitness: {average_fitness}, Average test fitness: {average_fitness_test}, Time elapsed: {time_elapsed}, Number of evaluations: {num_evals}\"\n",
    "            )\n",
    "            write_results_to_csv_fitness_improvement(\n",
    "                internal_nodes=internal_nodes,\n",
    "                leaf_nodes=leaf_nodes,\n",
    "                has_wind=has_wind,\n",
    "                reward_type=reward_type,\n",
    "                pop_size=64,\n",
    "                max_gens=max_gens,\n",
    "                best_training=best_training,\n",
    "                best_test=best_test,\n",
    "                average_fitness=average_fitness,\n",
    "                time_elapsed=time_elapsed,\n",
    "                num_evals=num_evals,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_fitness_test:\n",
    "    fitness_function_reward_types_exp(max_gens=50, has_wind=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_average_per_generation(csv_path, plot_type=\"Best\"):\n",
    "    \"\"\"\n",
    "    Method for averaging fitness values per generation across different experiment runs\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    column_name = \"best_training\"\n",
    "    if plot_type == \"Average\":\n",
    "        column_name = \"average_fitness\"\n",
    "\n",
    "    df[column_name] = df[column_name].apply(lambda s: eval(s, {\"np\": np}))\n",
    "    df[\"best_test\"] = df[\"best_test\"].apply(lambda s: eval(s, {\"np\": np}))\n",
    "\n",
    "    training_dict = defaultdict(list)\n",
    "    test_dict = defaultdict(list)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        training_dict[row[\"reward_type\"]].append(row[column_name])\n",
    "        test_dict[row[\"reward_type\"]].append(row[\"best_test\"])\n",
    "\n",
    "    # Average across runs for each generation\n",
    "    averaged_training = []\n",
    "    averaged_test = []\n",
    "    reward_types = []\n",
    "\n",
    "    for reward_type in sorted(training_dict.keys()):\n",
    "        reward_types.append(reward_type)\n",
    "\n",
    "        train_runs = np.array(training_dict[reward_type])\n",
    "        test_runs = np.array(test_dict[reward_type])\n",
    "\n",
    "        avg_train = np.mean(train_runs, axis=0).tolist()\n",
    "        avg_test = np.mean(test_runs, axis=0).tolist()\n",
    "\n",
    "        averaged_training.append(avg_train)\n",
    "        averaged_test.append(avg_test)\n",
    "\n",
    "    return averaged_training, averaged_test, reward_types\n",
    "\n",
    "\n",
    "def plot_fitnesses_reward_types_exp(\n",
    "    training_fitnesses, test_fitnesses, reward_types, plot_type=\"Best\", has_wind=False\n",
    "):\n",
    "    print(\"Training fitnesses:\", training_fitnesses)\n",
    "    print(\"Test fitnesses:\", test_fitnesses)\n",
    "    generations = list(range(len(training_fitnesses[0])))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Training fitness plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, reward_type in enumerate(reward_types):\n",
    "        plt.plot(generations, training_fitnesses[i], label=reward_type)\n",
    "    title_train = f\"{plot_type} Training Fitness over Generations {'with Wind' if has_wind else 'without Wind'}\"\n",
    "    plt.title(title_train)\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    if plot_type == \"Best\":\n",
    "        # Testing fitness plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for i, reward_type in enumerate(reward_types):\n",
    "            plt.plot(generations, test_fitnesses[i], label=reward_type)\n",
    "        title_test = f\"{plot_type} Testing Fitness over Generations {'with Wind' if has_wind else 'without Wind'}\"\n",
    "        plt.title(title_test)\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Fitness\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_fitness_test:\n",
    "    csv_path = (\n",
    "        \"improvement_results/fitness_comp_improvement_with_wind.csv\"  # or without wind\n",
    "    )\n",
    "    training_avg, test_avg, reward_types = load_and_average_per_generation(\n",
    "        csv_path, plot_type=\"Best\"\n",
    "    )\n",
    "    plot_fitnesses_reward_types_exp(\n",
    "        training_avg, test_avg, reward_types, plot_type=\"Best\", has_wind=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Operator Testing\n",
    "\n",
    "In this test, we will experiment with adding more operators as opposed to the basic arithmetic operators. The test setup will follow the following steps:\n",
    "\n",
    "1. First, test the best fitness (at the last generation) of the baseline implementation with the basic arithmetic operators.\n",
    "2. We will also test the fitness when we add more operators to the internal nodes set, specifically all the non-linear operators defined in the genepro/node_impl.py file. We expect the fitness to decrease, as the search space will be larger. This initial test is to see if this hypothesis holds.\n",
    "3. We will then give the algorithm more resources (twice the population size and twice the number of generations) and count which operators are present in the final trees. This will give us an idea of which operators are more useful in the context of the Lunar Lander environment.\n",
    "4. The top half of the operators will be selected and used in the next test. The bottom half will be discarded. Now, these operators will be tested against the basic operators, expecting the fitness to be higher than the basic operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_experimentation_loop(\n",
    "    internal_nodes,\n",
    "    pop_size=64,\n",
    "    max_gens=50,\n",
    "    max_tree_size=31,\n",
    "    crossover_rate=0.875,\n",
    "    mutation_rate=0.025,\n",
    "    coeff_opt_rate=0.1,\n",
    "    tournament_size=8,\n",
    "    has_wind=False,\n",
    ") -> tuple[ndarray[float], ndarray[float], list[Multitree]]:\n",
    "    # Define the best-performing hyperparameters\n",
    "    crossovers = [{\"fun\": subtree_crossover, \"rate\": crossover_rate}]\n",
    "    mutations = [{\"fun\": subtree_mutation, \"rate\": mutation_rate}]\n",
    "    coeff_opts = [{\"fun\": coeff_mutation, \"rate\": coeff_opt_rate}]\n",
    "    selection = {\n",
    "        \"fun\": tournament_selection,\n",
    "        \"kwargs\": {\"tournament_size\": tournament_size},\n",
    "    }\n",
    "\n",
    "    leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "    leaf_nodes = leaf_nodes + [Constant()]\n",
    "\n",
    "    # Initialize an evolution setup with the correct fitness function\n",
    "    evo = Evolution(\n",
    "        make_fitness_function_pt(reduction=\"sum\", has_wind=has_wind),\n",
    "        internal_nodes,\n",
    "        leaf_nodes,\n",
    "        n_trees=4,  # Number of trees in multitree is fixed to 4\n",
    "        # resource settings\n",
    "        pop_size=pop_size,\n",
    "        max_gens=max_gens,\n",
    "        max_tree_size=max_tree_size,\n",
    "        # hyperparameter settings\n",
    "        crossovers=crossovers,\n",
    "        mutations=mutations,\n",
    "        coeff_opts=coeff_opts,\n",
    "        selection=selection,\n",
    "        n_jobs=8,  # Number of jobs is fixed to 8 (used for parallel computing)\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Run the training loop for this evolution setup and get the fitnesses of the best individuals across generations\n",
    "    best_fitnesses_training, _, _, _ = evo.evolve()\n",
    "\n",
    "    best_fitnesses_test = np.array([get_test_score(tree) for tree in evo.best_of_gens])\n",
    "\n",
    "    return best_fitnesses_training, best_fitnesses_test, evo.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "CLASSNAME_TO_CLASS = {\n",
    "    \"Plus\": Plus,\n",
    "    \"Minus\": Minus,\n",
    "    \"Times\": Times,\n",
    "    \"Div\": Div,\n",
    "    \"Log\": Log,\n",
    "    \"Sqrt\": Sqrt,\n",
    "    \"Sin\": Sin,\n",
    "    \"Cos\": Cos,\n",
    "    \"Exp\": Exp,\n",
    "    \"Square\": Square,\n",
    "    \"Cube\": Cube,\n",
    "    \"Max\": Max,\n",
    "    \"Min\": Min,\n",
    "    \"Sign\": Sign,\n",
    "    \"Abs\": Abs,\n",
    "    \"Clamp\": Clamp,\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = \"operator_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "\n",
    "class OperatorResults:\n",
    "    def __init__(\n",
    "        self,\n",
    "        best_training: ndarray[float],\n",
    "        best_test: ndarray[float],\n",
    "        operator_count: defaultdict[str, int],\n",
    "        name: str,\n",
    "    ) -> None:\n",
    "        self.best_training = best_training\n",
    "        self.best_test = best_test\n",
    "        self.operator_count = operator_count\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "def count_operators(trees: list[Multitree]) -> defaultdict[str, int]:\n",
    "    d = defaultdict(int)\n",
    "    for tree in trees:\n",
    "        for node in tree.children:\n",
    "            if not (isinstance(node, Feature) or isinstance(node, Constant)):\n",
    "                d[type(node).__name__] += 1\n",
    "    return d\n",
    "\n",
    "\n",
    "def save_results_to_json(\n",
    "    results: OperatorResults, filename: str = \"operator_results.json\"\n",
    "):\n",
    "    import json\n",
    "\n",
    "    file_path = os.path.join(OUTPUT_DIR, filename)\n",
    "\n",
    "    data = {\n",
    "        \"best_training\": results.best_training[-1],\n",
    "        \"best_test\": results.best_test[-1],\n",
    "        \"operator_count\": dict(results.operator_count),\n",
    "    }\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "\n",
    "def plot_operator_fitness(\n",
    "    results: list[OperatorResults],\n",
    "    filename: str = \"operator_fitness_plot.png\",\n",
    "    has_wind: bool = False,\n",
    "):\n",
    "    file_path = os.path.join(OUTPUT_DIR, filename)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    for i, condition in enumerate([\"Training\", \"Testing\"]):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "\n",
    "        for result in results:\n",
    "            if i == 1:\n",
    "                plt.plot(result.best_test, label=result.name)\n",
    "            else:\n",
    "                plt.plot(result.best_training, label=result.name)\n",
    "\n",
    "        plt.title(\n",
    "            f\"Operator Experiment: Best {condition} Fitness over Generations \"\n",
    "            f\"{'with' if has_wind else 'without'} Wind\"\n",
    "        )\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Fitness\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "    plt.savefig(file_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_experiment(\n",
    "    operators,\n",
    "    filename,\n",
    "    experiment_name,\n",
    "    population_size=64,\n",
    "    max_generations=50,\n",
    "    has_wind=False,\n",
    "):\n",
    "    # Repeat experiment N times for robustness\n",
    "    N = 3\n",
    "\n",
    "    acc_best_training = np.zeros((N, max_generations + 1))\n",
    "    acc_best_test = np.zeros((N, max_generations + 1))\n",
    "    acc_population = []\n",
    "\n",
    "    for i in range(N):\n",
    "        print(f\"Running {experiment_name.lower()} experiment {i + 1}/{N}\")\n",
    "        best_training, best_test, final_population = operator_experimentation_loop(\n",
    "            operators,\n",
    "            max_gens=max_generations,\n",
    "            pop_size=population_size,\n",
    "            has_wind=has_wind,\n",
    "        )\n",
    "        acc_best_training[i] = best_training\n",
    "        acc_best_test[i] = best_test\n",
    "        acc_population += final_population\n",
    "\n",
    "    operators_used = count_operators(acc_population)\n",
    "\n",
    "    results = OperatorResults(\n",
    "        np.mean(acc_best_training, axis=0),\n",
    "        np.mean(acc_best_test, axis=0),\n",
    "        operators_used,\n",
    "        experiment_name,\n",
    "    )\n",
    "\n",
    "    save_results_to_json(results, filename)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_operator_test:\n",
    "    # Without wind\n",
    "    basic_operators = [Plus(), Minus(), Times(), Div()]\n",
    "    basic_results = operator_experiment(\n",
    "        basic_operators, \"basic.json\", \"Basic Operators\"\n",
    "    )\n",
    "\n",
    "    all_operators = basic_operators + [\n",
    "        Log(),\n",
    "        Sqrt(),\n",
    "        Sin(),\n",
    "        Cos(),\n",
    "        Exp(),\n",
    "        Square(),\n",
    "        Cube(),\n",
    "        Max(),\n",
    "        Min(),\n",
    "        Sign(),\n",
    "        Abs(),\n",
    "        Clamp(),\n",
    "    ]\n",
    "    all_ops_results = operator_experiment(\n",
    "        all_operators,\n",
    "        \"all_operators_small_resources.json\",\n",
    "        \"All Operators\",\n",
    "    )\n",
    "\n",
    "    all_ops_large_results = operator_experiment(\n",
    "        all_operators,\n",
    "        \"all_operators_more_resources.json\",\n",
    "        \"All Operators (More Resources)\",\n",
    "        population_size=256,\n",
    "        max_generations=100,\n",
    "    )\n",
    "\n",
    "    top8 = sorted(\n",
    "        all_ops_large_results.operator_count.items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True,\n",
    "    )[:8]\n",
    "    top8_operators = [CLASSNAME_TO_CLASS[name]() for name, _ in top8]\n",
    "\n",
    "    top8_results = operator_experiment(\n",
    "        top8_operators, \"top8_operators.json\", \"Top 8 Operators\"\n",
    "    )\n",
    "\n",
    "    # Plot the results (without wind)\n",
    "    all_results = [basic_results, all_ops_results, top8_results]\n",
    "    plot_operator_fitness(all_results, \"best_operator_fitness.png\")\n",
    "\n",
    "    # With wind\n",
    "    print(\"Running experiments with wind...\")\n",
    "    basic_results_wind = operator_experiment(\n",
    "        basic_operators, \"basic_wind.json\", \"Basic\", has_wind=True\n",
    "    )\n",
    "    all_ops_results_wind = operator_experiment(\n",
    "        all_operators,\n",
    "        \"all_operators_small_resources_wind.json\",\n",
    "        \"All Operators\",\n",
    "        has_wind=True,\n",
    "    )\n",
    "    top8_results_wind = operator_experiment(\n",
    "        top8_operators, \"top8_wind.json\", \"Top 8 Operators\", has_wind=True\n",
    "    )\n",
    "\n",
    "    # Plot the results (with wind)\n",
    "    plot_operator_fitness(\n",
    "        [basic_results_wind, all_ops_results_wind, top8_results_wind],\n",
    "        \"best_operator_fitness_wind.png\",\n",
    "        has_wind=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3. Multi-objective Optimization\n",
    "\n",
    "We will take diversity into account in addition to fitness. Hence, we will select the best parents by creating a Pareto front and optimizing against maximizing diversity and fitness. For this purpose, we will use the fast non-dominated sorting algorithm and maximum Pareto domination. \n",
    "\n",
    "Reformulating the problem as a multi-objective problem is important to overcome the problem of having very similar individuals in the population after a few rounds of the algorithm, possibly forcing the algorithm to converge on a sub-optimal solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_to_csv_multiobjective(\n",
    "    internal_nodes,\n",
    "    leaf_nodes,\n",
    "    has_wind,\n",
    "    reward_type,\n",
    "    is_multiobjective,\n",
    "    pop_size,\n",
    "    max_gens,\n",
    "    best_training,\n",
    "    best_test,\n",
    "    average_fitness,\n",
    "    time_elapsed,\n",
    "    num_evals,\n",
    "):\n",
    "\n",
    "    # Flatten node types to strings for logging\n",
    "    internal_str = \",\".join(type(node).__name__ for node in internal_nodes)\n",
    "    leaf_str = \",\".join(type(node).__name__ for node in leaf_nodes)\n",
    "\n",
    "    # Build a dictionary of all results/settings\n",
    "    row = {\n",
    "        \"internal_nodes\": internal_str,\n",
    "        \"leaf_nodes\": leaf_str,\n",
    "        \"has_wind\": has_wind,\n",
    "        \"reward_type\": reward_type,\n",
    "        \"is_multiobjective\": is_multiobjective,\n",
    "        \"pop_size\": pop_size,\n",
    "        \"max_gens\": max_gens,\n",
    "        \"best_training\": best_training,\n",
    "        \"best_test\": best_test,\n",
    "        \"average_fitness\": average_fitness,\n",
    "        \"time_elapsed\": time_elapsed,\n",
    "        \"num_evals\": num_evals,\n",
    "    }\n",
    "\n",
    "    name = \"multiobjective_improvement.csv\"\n",
    "    if has_wind:\n",
    "        name = \"multiobjective_improvement.csv\"\n",
    "\n",
    "    os.makedirs(\"improvement_results\", exist_ok=True)\n",
    "    filename = os.path.join(\"improvement_results\", name)\n",
    "\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=list(row.keys()))\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "def multiobjective_exp(max_gens=30, has_wind=False, is_multiobjective=True):\n",
    "    reward_type = \"avg\"\n",
    "    fitness_function_version = make_fitness_function_pt(\n",
    "        reduction=reward_type, has_wind=has_wind\n",
    "    )\n",
    "    print(f\"\\nRunning experiment multi-objective case: {is_multiobjective}\")\n",
    "    (\n",
    "        best_training,\n",
    "        best_test,\n",
    "        average_fitness,\n",
    "        average_fitness_test,\n",
    "        time_elapsed,\n",
    "        num_evals,\n",
    "    ) = main_experimentation_loop(\n",
    "        fitness_function_version,\n",
    "        internal_nodes,\n",
    "        leaf_nodes,\n",
    "        pop_size=16,\n",
    "        max_gens=max_gens,\n",
    "        max_tree_size=31,\n",
    "        is_multiobjective=is_multiobjective,\n",
    "    )\n",
    "    print(\n",
    "        f\"Best training fitness: {best_training}, Best test fitness: {best_test}, Average fitness: {average_fitness}, Average test fitness: {average_fitness_test}, Time elapsed: {time_elapsed}, Number of evaluations: {num_evals}\"\n",
    "    )\n",
    "    write_results_to_csv_multiobjective(\n",
    "        internal_nodes=internal_nodes,\n",
    "        leaf_nodes=leaf_nodes,\n",
    "        has_wind=has_wind,\n",
    "        reward_type=reward_type,\n",
    "        is_multiobjective=is_multiobjective,\n",
    "        pop_size=16,\n",
    "        max_gens=max_gens,\n",
    "        best_training=best_training,\n",
    "        best_test=best_test,\n",
    "        average_fitness=average_fitness,\n",
    "        time_elapsed=time_elapsed,\n",
    "        num_evals=num_evals,\n",
    "    )\n",
    "\n",
    "\n",
    "if perform_multiobjective_test:\n",
    "    multiobjective_exp(max_gens=10, has_wind=False, is_multiobjective=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an animation\n",
    "Here the best evolved individual is selected and one episode is rendered. Make sure to save your lunar landers over time to track progress and make comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gist to save gif from https://gist.github.com/botforge/64cbb71780e6208172bbf03cd9293553\n",
    "def save_frames_as_gif(frames, path=\"./\", filename=\"evolved_lander.gif\"):\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames), interval=50)\n",
    "    anim.save(path + filename, writer=\"imagemagick\", fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_normal_evolution:\n",
    "    frames = []\n",
    "    fitness_function_pt(\n",
    "        best, num_episodes=1, episode_duration=500, render=True, ignore_done=False\n",
    "    )\n",
    "    env.close()\n",
    "    save_frames_as_gif(frames, filename=\"evolved_lander_RL.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "The coefficients in the multi-tree aren't optimised. Here Q-learning (taken from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) is used to optimise the weights further. Incorporate coefficient optimisation in training your agent(s). Coefficient Optimisation can be expensive. Think about how often you want to optimise, when, which individuals etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_normal_evolution:\n",
    "    batch_size = 128\n",
    "    GAMMA = 0.99\n",
    "\n",
    "    constants = best.get_subtrees_consts()\n",
    "\n",
    "    if len(constants) > 0:\n",
    "        optimizer = optim.AdamW(constants, lr=1e-3, amsgrad=True)\n",
    "\n",
    "    for _ in range(500):\n",
    "\n",
    "        if len(constants) > 0 and len(evo.memory) > batch_size:\n",
    "            target_tree = copy.deepcopy(best)\n",
    "\n",
    "            transitions = evo.memory.sample(batch_size)\n",
    "            batch = Transition(*zip(*transitions))\n",
    "\n",
    "            non_final_mask = torch.tensor(\n",
    "                tuple(map(lambda s: s is not None, batch.next_state)), dtype=torch.bool\n",
    "            )\n",
    "\n",
    "            non_final_next_states = torch.cat(\n",
    "                [s for s in batch.next_state if s is not None]\n",
    "            )\n",
    "            state_batch = torch.cat(batch.state)\n",
    "            action_batch = torch.cat(batch.action)\n",
    "            reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "            state_action_values = best.get_output_pt(state_batch).gather(\n",
    "                1, action_batch\n",
    "            )\n",
    "            next_state_values = torch.zeros(batch_size, dtype=torch.float)\n",
    "            with torch.no_grad():\n",
    "                next_state_values[non_final_mask] = (\n",
    "                    target_tree.get_output_pt(non_final_next_states).max(1)[0].float()\n",
    "                )\n",
    "\n",
    "            expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "            criterion = nn.SmoothL1Loss()\n",
    "            loss = criterion(\n",
    "                state_action_values, expected_state_action_values.unsqueeze(1)\n",
    "            )\n",
    "\n",
    "            # Optimize the model\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(constants, 100)\n",
    "            optimizer.step()\n",
    "\n",
    "    print(best.get_readable_repr())\n",
    "    print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander_RL.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Plots\n",
    "\n",
    "Below are some plotting cells used to gauge the right hyperparameters for the GP algorithm. The plots are generated from the results of the hyperparameter tuning experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hyperparameter_tuning_results/resultscombined\")\n",
    "\n",
    "parameters = [\"crossover_rate\", \"mutation_rate\", \"coeff_opt_rate\", \"tournament_size\"]\n",
    "\n",
    "# little wonky conversion to take the last float because the array looks like \"[np.float64(-134359.23), np.float64(-213.35), ...\n",
    "df[\"average_fitness\"] = df[\"average_fitness\"].apply(\n",
    "    lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3])\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, param in enumerate(parameters):\n",
    "    ax = axes[i]\n",
    "    df.boxplot(column=\"average_fitness\", by=param, ax=ax)\n",
    "    # ax.scatter(df[param], df['average_fitness'], alpha=0.5)\n",
    "    ax.set_xlabel(param)\n",
    "    ax.set_ylabel(\"average_fitness\")\n",
    "    ax.set_title(f\"{param} vs average_fitness\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(\"hyperparameter_tuning_results/resultscombined\")\n",
    "df[\"best_training\"] = df[\"best_training\"].apply(\n",
    "    lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3])\n",
    ")\n",
    "df = df[df[\"tournament_size\"] == 8]\n",
    "# Create 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    df,\n",
    "    x=\"crossover_rate\",\n",
    "    y=\"mutation_rate\",\n",
    "    z=\"coeff_opt_rate\",\n",
    "    color=\"best_training\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    opacity=0.8,\n",
    "    title=\"3D Scatter Plot of Hyperparameters vs Average Fitness\",\n",
    "    labels={\n",
    "        \"crossover_rate\": \"Crossover Rate\",\n",
    "        \"mutation_rate\": \"Mutation Rate\",\n",
    "        \"coeff_opt_rate\": \"Coeff Opt Rate\",\n",
    "        \"best_training\": \"Best Fitness\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Set renderer (if needed)\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = (\n",
    "    \"browser\"  # Try 'iframe_connected' or 'browser' if this doesn't show\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Heatmap with One Facet: Coeff Opt Rate\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"hyperparameter_tuning_results/resultscombined\")\n",
    "df[\"best_training\"] = df[\"best_training\"].apply(\n",
    "    lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3])\n",
    ")\n",
    "df = df[df[\"tournament_size\"] == 8]\n",
    "\n",
    "# Round to avoid floating point noise in axes\n",
    "df[\"crossover_rate\"] = df[\"crossover_rate\"].round(3)\n",
    "df[\"mutation_rate\"] = df[\"mutation_rate\"].round(3)\n",
    "df[\"coeff_opt_rate\"] = df[\"coeff_opt_rate\"].round(3)\n",
    "\n",
    "# Create faceted heatmaps\n",
    "fig = px.density_heatmap(\n",
    "    df,\n",
    "    x=\"crossover_rate\",\n",
    "    y=\"mutation_rate\",\n",
    "    z=\"best_training\",\n",
    "    facet_col=\"coeff_opt_rate\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    histfunc=\"avg\",\n",
    "    title=\"Hyperparameter Heatmaps: Fitness vs Crossover & Mutation (Faceted by Coeff Opt Rate)\",\n",
    "    labels={\n",
    "        \"crossover_rate\": \"Crossover Rate\",\n",
    "        \"mutation_rate\": \"Mutation Rate\",\n",
    "        \"best_training\": \"Best Fitness\",\n",
    "        \"coeff_opt_rate\": \"Coeff Opt Rate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=50, b=20))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Heatmap with Two Facets: Coeff Opt Rate and Tournament Size\n",
    "# This heatmap uses best_fitness metric for selection\n",
    "# and averages this metric across generations\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"hyperparameter_tuning_results/resultscombined\")\n",
    "\n",
    "# Extract float value from 'best_training' column\n",
    "df[\"best_training\"] = df[\"best_training\"].apply(\n",
    "    lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3])\n",
    ")\n",
    "\n",
    "# Round to avoid floating point noise in axes\n",
    "df[\"crossover_rate\"] = df[\"crossover_rate\"].round(3)\n",
    "df[\"mutation_rate\"] = df[\"mutation_rate\"].round(3)\n",
    "df[\"coeff_opt_rate\"] = df[\"coeff_opt_rate\"].round(3)\n",
    "df[\"tournament_size\"] = df[\"tournament_size\"]\n",
    "\n",
    "# Remove configuration where crossover_rate == 1.0\n",
    "df = df[df[\"crossover_rate\"] != 1.0]\n",
    "\n",
    "# Create faceted heatmaps with mutation_rate as row facet and crossover_rate as column facet\n",
    "fig = px.density_heatmap(\n",
    "    df,\n",
    "    x=\"tournament_size\",\n",
    "    y=\"coeff_opt_rate\",\n",
    "    z=\"best_training\",\n",
    "    facet_row=\"mutation_rate\",\n",
    "    facet_col=\"crossover_rate\",\n",
    "    histfunc=\"avg\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    title=\"Fitness Heatmaps: Tournament Size vs Coeff Opt Rate (Faceted by Mutation & Crossover Rate)\",\n",
    "    labels={\n",
    "        \"tournament_size\": \"Tournament Size\",\n",
    "        \"coeff_opt_rate\": \"Coeff Opt Rate\",\n",
    "        \"best_training\": \"Best Fitness\",\n",
    "        \"mutation_rate\": \"Mutation Rate\",\n",
    "        \"crossover_rate\": \"Crossover Rate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Improve layout\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=60, b=20), height=800, width=1000)\n",
    "\n",
    "# Reduce font size of facet labels to prevent overlap\n",
    "for annotation in fig.layout.annotations:\n",
    "    annotation.font.size = 10\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Heatmap with Two Facets: Coeff Opt Rate and Tournament Size\n",
    "# This heatmap uses avg_fitness metric for selection\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"hyperparameter_tuning_results/resultscombined\")\n",
    "\n",
    "# Extract float value from 'average_fitness' column\n",
    "df[\"average_fitness\"] = df[\"average_fitness\"].apply(\n",
    "    lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3])\n",
    ")\n",
    "\n",
    "# Round to avoid floating point noise in axes\n",
    "df[\"crossover_rate\"] = df[\"crossover_rate\"].round(3)\n",
    "df[\"mutation_rate\"] = df[\"mutation_rate\"].round(3)\n",
    "df[\"coeff_opt_rate\"] = df[\"coeff_opt_rate\"].round(3)\n",
    "df[\"tournament_size\"] = df[\"tournament_size\"]\n",
    "\n",
    "# Create faceted heatmaps with tournament_size as row facet and coeff_opt_rate as column facet\n",
    "fig = px.density_heatmap(\n",
    "    df,\n",
    "    x=\"crossover_rate\",\n",
    "    y=\"mutation_rate\",\n",
    "    z=\"average_fitness\",\n",
    "    facet_row=\"tournament_size\",  #  Add tournament_size as row facet\n",
    "    facet_col=\"coeff_opt_rate\",  #  Coeff mutation rate as column facet\n",
    "    histfunc=\"avg\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    title=\"Fitness Heatmaps: Crossover vs Mutation (Faceted by Coeff Opt Rate and Tournament Size)\",\n",
    "    labels={\n",
    "        \"crossover_rate\": \"Crossover Rate\",\n",
    "        \"mutation_rate\": \"Mutation Rate\",\n",
    "        \"average_fitness\": \"Average Fitness\",\n",
    "        \"coeff_opt_rate\": \"Coeff Opt Rate\",\n",
    "        \"tournament_size\": \"Tournament Size\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Improve layout\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=60, b=20), height=800, width=1000)\n",
    "\n",
    "for annotation in fig.layout.annotations:\n",
    "    annotation.font.size = 10\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(\"hyperparameter_tuning_results/resultscombined\")\n",
    "df[\"best_training\"] = df[\"best_training\"].apply(\n",
    "    lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3])\n",
    ")\n",
    "\n",
    "# Filter by tournament_size and a fixed coeff_opt_rate value (adjust if needed)\n",
    "df = df[df[\"tournament_size\"] == 8]\n",
    "df[\"coeff_opt_rate\"] = df[\"coeff_opt_rate\"].round(3)\n",
    "target_coeff = df[\"coeff_opt_rate\"].unique()[0]  # Use first value or set manually\n",
    "df = df[df[\"coeff_opt_rate\"] == target_coeff]\n",
    "\n",
    "# Round to reduce float precision issues\n",
    "df[\"crossover_rate\"] = df[\"crossover_rate\"].round(3)\n",
    "df[\"mutation_rate\"] = df[\"mutation_rate\"].round(3)\n",
    "\n",
    "# Pivot data to create Z-matrix\n",
    "pivot_df = df.pivot_table(\n",
    "    values=\"best_training\",\n",
    "    index=\"mutation_rate\",\n",
    "    columns=\"crossover_rate\",\n",
    "    aggfunc=\"mean\",  # or 'min' depending on your definition of \"best\"\n",
    ")\n",
    "\n",
    "# Extract axes\n",
    "x = pivot_df.columns.values  # crossover_rate\n",
    "y = pivot_df.index.values  # mutation_rate\n",
    "z = pivot_df.values  # best_training\n",
    "\n",
    "# Create 3D surface plot\n",
    "fig = go.Figure(data=[go.Surface(z=z, x=x, y=y, colorscale=\"Viridis\")])\n",
    "fig.update_layout(\n",
    "    title=\"Average Fitness vs Hyperparameters\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Crossover Rate\",\n",
    "        yaxis_title=\"Mutation Rate\",\n",
    "        zaxis_title=\"Average Fitness\",\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
