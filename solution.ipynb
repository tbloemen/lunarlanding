{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving a Lunar Lander with differentiable Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "To install the required libraries run the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports from the standard genepro-multi library are done here. Any adjustments (e.g. different operators) should be made in the notebook. For example:\n",
    "\n",
    "```\n",
    "class SmoothOperator(Node):\n",
    "  def __init__(self):\n",
    "    super(SmoothOperator,self).__init__()\n",
    "    self.arity = 1\n",
    "    self.symb = \"SmoothOperator\"\n",
    "\n",
    "  def _get_args_repr(self, args):\n",
    "    return self._get_typical_repr(args,'before')\n",
    "\n",
    "  def get_output(self, X):\n",
    "    c_outs = self._get_child_outputs(X)\n",
    "    return np.smoothOperation(c_outs[0])\n",
    "\n",
    "  def get_output_pt(self, X):\n",
    "    c_outs = self._get_child_outputs_pt(X)\n",
    "    return torch.smoothOperation(c_outs[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from genepro.node_impl import *\n",
    "from genepro.evo import Evolution\n",
    "from genepro.node_impl import Constant\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Setup\n",
    "Here we first setup the Gymnasium environment. Please see https://gymnasium.farama.org/environments/box2d/lunar_lander/ for more information on the environment. \n",
    "\n",
    "Then a memory buffer is made. This is a buffer in which state transitions are stored. When the buffer reaches its maximum capacity old transitions are replaced by new ones.\n",
    "\n",
    "A frame buffer is initialised, used to later store animation frames of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Wind\n",
    "\n",
    "Wind can be added to the current environment setup as below:\n",
    "\n",
    "```bash\n",
    "env = gym.make(\"LunarLander-v3\", continuous=False,\n",
    "               enable_wind=True, wind_power=15.0, turbulence_power=1.5)\n",
    "```\n",
    "\n",
    "Selin: When we add wind as a variable, it makes sense to also edit our fitness function. We can define a new boolean parameter (say have_random_wind) and if it is set to true when the fitness function is called, we can re-define the environment with a random wind value at each episode. This would potentially make our GP algorithm more robust to randomness. A possible implementation:\n",
    "\n",
    "```bash\n",
    "if use_random_wind:\n",
    "    env = gym.make(\"LunarLander-v3\", continuous=False,\n",
    "                    enable_wind=True,\n",
    "                    wind_power=np.random.uniform(5.0, 20.0),\n",
    "                    turbulence_power=np.random.uniform(0.5, 2.0))\n",
    "```\n",
    "\n",
    "The above can be added within the loop that goes over the episodes (the outer for loop of the fitness function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new Atomic Functions\n",
    "\n",
    "These atomic functions will be added as internal nodes within the Evolution setup.\n",
    "\n",
    "We can add min & max operators. Or instead, we can add **Clamp(x, min, max)** operator. This could be interesting.\n",
    "\n",
    "We can add domain specific operators:\n",
    "- Maybe a function that calculates the angle of the lunarlander to the pad (angle_to_pad(x_pos, y_pos)?)\n",
    "\n",
    "#### Fitness Calculation\n",
    "\n",
    "For the final fitness calculation, we are taking the sum of the rewards across episodes. Instead of sum operation, can we do this fitness calculation in a more clever way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "      self.memory += other.memory\n",
    "      return self \n",
    "\n",
    "    def __add__(self, other):\n",
    "      self.memory = self.memory + other.memory \n",
    "      return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function\n",
    "\n",
    "Here you get to be creative. The default setup evaluates 5 episodes of 300 frames. Think of what action to pick and what fitness function to use. The Multi-tree takes an input of $n \\times d$ where $n$ is a batch of size 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selin's Notes\n",
    "\n",
    "**Fitness Function:** Fitness is defined as the cumulative reward of the landing.\n",
    "\n",
    "**Multitree:** Multitree contains 4 trees, one for each action of the Lunar lander. \n",
    "\n",
    "- `0`: do nothing\n",
    "- `1`: fire left orientation engine\n",
    "- `2`: fire main engine\n",
    "- `3`: fire right orientation engine\n",
    "\n",
    "Multitree is initialized under genepro/variation.py file, with the generate_random_multitree() method. This method is called in the genepro/evo.py file within the _initialize_population() internal method. \n",
    "\n",
    "**Understanding the Input Sample:** Input sample is an 8-dimensional vector: [x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact]\n",
    "\n",
    "e.g. [-2.5, -2.5, -10, -10, -6.28, -10, 0, 0]\n",
    "\n",
    "- index0 : x position of the lander\n",
    "- index1: y position of the lander\n",
    "- index2: velocity in the x direction\n",
    "- index3: velocity in the y direction\n",
    "- index4: angle of the lander\n",
    "- index5: angular velocity\n",
    "- index6: leg 1 in contact\n",
    "- index7: leg 2 in contact\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fitness_function_pt(reduction='sum', has_wind=False):\n",
    "  '''\n",
    "  Generic fitness function factory\n",
    "  '''\n",
    "  def fitness_function(multitree, num_episodes=5, episode_duration=300, render=False, ignore_done=False):\n",
    "    memory = ReplayMemory(10000)\n",
    "    rewards = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "      # get initial state of the environment\n",
    "      if has_wind: \n",
    "        env = gym.make(\"LunarLander-v3\", continuous=False,\n",
    "                        enable_wind=True,\n",
    "                        wind_power=np.random.uniform(5.0, 20.0),\n",
    "                        turbulence_power=np.random.uniform(0.5, 2.0))\n",
    "      else:\n",
    "        env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "        \n",
    "      observation = env.reset()\n",
    "      observation = observation[0]\n",
    "      \n",
    "      for _ in range(episode_duration):\n",
    "        if render:\n",
    "          frames.append(env.render())\n",
    "\n",
    "        input_sample = torch.from_numpy(observation.reshape((1,-1))).float() # Input sample is a torch tensor\n",
    "\n",
    "        # what goes here? TODO\n",
    "        '''Below is Selin's possible definition of an action'''\n",
    "        output_scores = multitree.get_output_pt(input_sample) # A tensor of length 4, storing the scores of each action (after evaluating each tree)\n",
    "        action = torch.argmax(output_scores, dim=1) # Select the action with the highest score\n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        rewards.append(reward)\n",
    "        output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        memory.push(input_sample, torch.tensor([[action.item()]]), output_sample, torch.tensor([reward]))\n",
    "        if (terminated or truncated) and not ignore_done:\n",
    "          break\n",
    "          \n",
    "    # Define the reward types here\n",
    "    if reduction == 'sum':\n",
    "      fitness = np.sum(rewards)\n",
    "    elif reduction == 'min':\n",
    "      fitness = np.min(rewards)\n",
    "    else:\n",
    "      raise ValueError(f\"Unknown reduction method: {reduction}\")\n",
    "    \n",
    "    return fitness, memory\n",
    "  \n",
    "  return fitness_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Setup\n",
    "Here the leaf and internal nodes are defined. Think about the odds of sampling a constant in this default configurations. Also think about any operators that could be useful and add them here. \n",
    "\n",
    "Adjust the population size (multiple of 8 if you want to use the standard tournament selection), max generations and max tree size to taste. Be aware that each of these settings can increase the runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selin's ideas about the things they wanted us to consider in the evolution setup (possible areas for improvement)\n",
    "\n",
    "In the below code, it says **Think about the probability of sampling a coefficient (which is basically a constant).** Currently, in the below code, we have 8 features and we are adding all of them as leaf nodes. \n",
    "\n",
    "However, we are only adding 1 constant as a leaf node. So this would give us a 1/9 chance of sampling a coefficient. This is a very small probability. Hence, **a possible area of improvement** might be to consider adding more constants (e.g. 4 or 5 constants) to our leaf nodes set and see how our GP performs. I think having constant is **important** because they allow the model to shift or scale features (e.g. x_4 + 1.5).\n",
    "\n",
    "**Having more operators:** Currently, we only have basic arithmetic operators. We can add the following non-linear operators:\n",
    "- log\n",
    "- sqrt\n",
    "- sin, cos\n",
    "- max, min\n",
    "- exp\n",
    "- square, cube, ...\n",
    "\n",
    "**Adjusting the parameters of the Evolution() method** called below. We can design an experiment to find the best combination of parameter values for population size, max generations, and max tree size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [Constant()] # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [Plus(),Minus(),Times(),Div()] # Add your own operators here\n",
    "\n",
    "fitness_function_pt = make_fitness_function_pt(reduction='sum') # Baseline fitness function\n",
    "\n",
    "evo = Evolution(\n",
    "  fitness_function_pt, internal_nodes, leaf_nodes,\n",
    "  4,\n",
    "  pop_size=16,\n",
    "  max_gens=10,\n",
    "  max_tree_size=31,\n",
    "  n_jobs=8,\n",
    "  verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolve\n",
    "Running this cell will use all the settings above as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DIVERSION:  [25, 12, 25, 15, 25, 62, 15, 24, 24, 13, 30, 61, 14, 25, 12, 30]\n",
      "gen: 1,\tbest of gen fitness: -537.718,\tbest of gen size: 27\n",
      "\n",
      "DIVERSION:  [26, 4, 70, 27, 20, 17, 17, 34, 34, 14, 34, 26, 14, 27, 34, 34]\n",
      "gen: 2,\tbest of gen fitness: -520.093,\tbest of gen size: 29\n",
      "\n",
      "DIVERSION:  [54, 46, 46, 54, 49, 49, 49, 49, 54, 47, 50, 53, 53, 44, 50, 53]\n",
      "gen: 3,\tbest of gen fitness: -504.528,\tbest of gen size: 27\n",
      "\n",
      "DIVERSION:  [55, 55, 49, 49, 50, 49, 55, 48, 55, 50, 46, 55, 51, 49, 55, 55]\n",
      "gen: 4,\tbest of gen fitness: -428.597,\tbest of gen size: 29\n",
      "\n",
      "DIVERSION:  [59, 57, 45, 45, 59, 57, 57, 57, 57, 57, 45, 57, 57, 57, 57, 57]\n",
      "gen: 5,\tbest of gen fitness: -452.722,\tbest of gen size: 29\n",
      "\n",
      "DIVERSION:  [50, 50, 50, 30, 30, 37, 42, 38, 50, 50, 50, 50, 27, 50, 50, 40]\n",
      "gen: 6,\tbest of gen fitness: -289.605,\tbest of gen size: 29\n",
      "\n",
      "DIVERSION:  [37, 73, 41, 43, 41, 43, 41, 31, 37, 41, 41, 43, 41, 43, 31, 31]\n",
      "gen: 7,\tbest of gen fitness: -470.358,\tbest of gen size: 29\n",
      "\n",
      "DIVERSION:  [57, 51, 54, 51, 84, 75, 54, 57, 75, 54, 58, 75, 50, 50, 57, 50]\n",
      "gen: 8,\tbest of gen fitness: -489.446,\tbest of gen size: 29\n",
      "\n",
      "DIVERSION:  [60, 72, 72, 36, 60, 75, 60, 72, 72, 63, 72, 60, 75, 60, 72, 75]\n",
      "gen: 9,\tbest of gen fitness: -326.437,\tbest of gen size: 29\n",
      "\n",
      "DIVERSION:  [64, 70, 72, 59, 64, 61, 56, 51, 64, 69, 64, 51, 64, 49, 70, 64]\n",
      "gen: 10,\tbest of gen fitness: -359.451,\tbest of gen size: 29\n"
     ]
    }
   ],
   "source": [
    "best_fitnesses_across_gens = evo.evolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-537.7176717811469, -520.0929867524105, -504.52821380497244, -428.59714932583876, -452.72181872486635, -289.60467941080014, -470.3578960426664, -489.4456615025033, -326.43719631076783, -359.45071770919867]\n"
     ]
    }
   ],
   "source": [
    "print(best_fitnesses_across_gens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['((((x_4*x_5)*(x_3+x_4))/(x_1+(x_1/0.4374861419200897)))+(((x_5*x_3)-(x_3+x_1))/((x_1-x_4)-(x_4+3.9795982837677))))', '((((x_6-x_1)*(x_2--0.39744412899017334))+((x_4-x_2)/x_3))+((x_6-x_7)-((x_0+x_7)+x_7)))', '((((x_6*x_7)-(x_4*x_7))*(-4.209872722625732+(x_7/x_5)))-((x_5+(x_1-x_7))+x_5))', '((((x_4/x_3)*x_6)+((x_2*x_0)/(-1.972465265770838+x_3)))/(((x_7/x_0)-(x_4+x_5))-(x_4+x_5)))']\n",
      "-1507.6600345063994\n"
     ]
    }
   ],
   "source": [
    "def get_test_score(tree):\n",
    "    rewards = []\n",
    "\n",
    "    for i in range(10):\n",
    "      # get initial state\n",
    "      observation = env.reset(seed=i)\n",
    "      observation = observation[0]\n",
    "\n",
    "      for _ in range(500):    \n",
    "        # build up the input sample for GP\n",
    "        input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        \n",
    "        # TODO: Again, define the action\n",
    "        '''Selin's idea of an action is added below'''\n",
    "        # get output (squeezing because it is encapsulated in an array)\n",
    "        output = tree.get_output_pt(input_sample)\n",
    "        action = torch.argmax(output, dim=1) # Select the action with the highest score\n",
    "        \n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        rewards.append(reward)\n",
    "        output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        if (terminated or truncated):\n",
    "            break\n",
    "\n",
    "    fitness = np.sum(rewards)\n",
    "    \n",
    "    return fitness\n",
    "\n",
    "best = evo.best_of_gens[-1]\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Experimentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nConfiguring the fitness function\\nTEST 1.1 Single objective: Experiment with different quality metrics for fitness\\nTEST 1.2 Multi-objective: Include diversity as a second metric\\n\\nRequired additional arguments for fitness function: has_wind=False, reward_type='sum', is_multiobjective=False\\nwhere reward_types = ['sum', 'min', 'weighted_sum']\\n\\nWind Test \\nAdding wind as a variable, and also adding a random wind value at each episode\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write down ideas for experimentation here!\n",
    "\n",
    "# TEST TYPE 1. Improving the Fitness Function\n",
    "'''\n",
    "Configuring the fitness function\n",
    "TEST 1.1 Single objective: Experiment with different quality metrics for fitness\n",
    "TEST 1.2 Multi-objective: Include diversity as a second metric\n",
    "\n",
    "Required additional arguments for fitness function: has_wind=False, reward_type='sum', is_multiobjective=False\n",
    "where reward_types = ['sum', 'min', 'weighted_sum']\n",
    "\n",
    "Wind Test \n",
    "Adding wind as a variable, and also adding a random wind value at each episode\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment for reward type: sum\n",
      "\n",
      "DIVERSION:  [2, 19, 2, 19, 3, 23, 23, 4, 23, 3, 4, 17, 0, 19, 17, 2]\n",
      "gen: 1,\tbest of gen fitness: -579.567,\tbest of gen size: 29\n",
      "\n",
      "DIVERSION:  [27, 34, 29, 35, 35, 37, 43, 37, 37, 43, 35, 43, 35, 43, 28, 43]\n",
      "gen: 2,\tbest of gen fitness: -485.137,\tbest of gen size: 29\n",
      "\n",
      "Running experiment for reward type: min\n",
      "\n",
      "DIVERSION:  [0, 0, 4, 0, 0, 0, 0, 5, 7, 3, 0, 3, 7, 0, 5, 6]\n",
      "gen: 1,\tbest of gen fitness: -100.000,\tbest of gen size: 27\n",
      "\n",
      "DIVERSION:  [2, 7, 3, 7, 6, 3, 6, 3, 7, 4, 0, 0, 0, 7, 2, 3]\n",
      "gen: 2,\tbest of gen fitness: -100.000,\tbest of gen size: 27\n"
     ]
    }
   ],
   "source": [
    "# TODO: Think about how to incorporate wind to the experimentation setup!!!\n",
    "\n",
    "def main_experimentation_loop(fitness_function_version, internal_nodes, leaf_nodes,\n",
    "                                pop_size=16, max_gens=10, max_tree_size=31):\n",
    "            \n",
    "    # Initialize an evolution setup with the correct fitness function\n",
    "    evo = Evolution(\n",
    "            fitness_function_version, \n",
    "            internal_nodes, \n",
    "            leaf_nodes,\n",
    "            n_trees=4, # Number of trees in multitree is fixed to 4\n",
    "            pop_size=pop_size,\n",
    "            max_gens=max_gens,\n",
    "            max_tree_size=max_tree_size,\n",
    "            n_jobs=8, # Number of jobs is fixed to 8\n",
    "            verbose=True)\n",
    "    \n",
    "    # Run the training loop for this evolution setup and get the fitnesses of the best individuals across generations\n",
    "    best_fitnesses_training = evo.evolve()\n",
    "\n",
    "    # Now, run the testing loop for this evolution setup and get the fitnesses of the best individuals across generations\n",
    "    # Extract best-of-generation trees\n",
    "    best_individuals = evo.best_of_gens\n",
    "\n",
    "    # Collect test scores for each best individual\n",
    "    best_fitnesses_test = [\n",
    "        get_test_score(ind) for ind in best_individuals\n",
    "    ]\n",
    "\n",
    "    return best_fitnesses_training, best_fitnesses_test\n",
    "\n",
    "\n",
    "def plot_fitnesses(training_fitnesses, test_fitnesses, reward_types):\n",
    "    generations = list(range(len(training_fitnesses[0])))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Training fitness plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, reward_type in enumerate(reward_types):\n",
    "        plt.plot(generations, training_fitnesses[i], label=reward_type)\n",
    "    plt.title(\"Training Fitness over Generations\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Testing fitness plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i, reward_type in enumerate(reward_types):\n",
    "        plt.plot(generations, test_fitnesses[i], label=reward_type)\n",
    "    plt.title(\"Testing Fitness over Generations\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# TEST TYPE 1. Improving the Fitness Function\n",
    "'''\n",
    "Configuring the fitness function\n",
    "TEST 1.1 Single objective: Experiment with different quality metrics for fitness\n",
    "TEST 1.2 Multi-objective: Include diversity as a second metric\n",
    "\n",
    "Required additional arguments for fitness function: has_wind=False, reward_type='sum', is_multiobjective=False\n",
    "where reward_types = ['sum', 'min', 'weighted_sum']\n",
    "\n",
    "Wind Test \n",
    "Adding wind as a variable, and also adding a random wind value at each episode\n",
    "''' \n",
    "def fitness_function_reward_types_exp(max_gens=10):\n",
    "    reward_types = ['sum', 'min']\n",
    "    training_fitnesses = []\n",
    "    test_fitnesses = []\n",
    "    for reward_type in reward_types:\n",
    "        fitness_function_version = make_fitness_function_pt(reduction=reward_type)\n",
    "        print(f\"\\nRunning experiment for reward type: {reward_type}\")\n",
    "        best_training, best_test = main_experimentation_loop(fitness_function_version, \n",
    "                                                             internal_nodes, \n",
    "                                                             leaf_nodes,\n",
    "                                                             pop_size=16, \n",
    "                                                             max_gens=max_gens, \n",
    "                                                             max_tree_size=31)\n",
    "        training_fitnesses.append(best_training)\n",
    "        test_fitnesses.append(best_test)\n",
    "\n",
    "    return training_fitnesses, test_fitnesses, reward_types\n",
    "\n",
    "\n",
    "training_fitnesses, test_fitnesses, reward_types = fitness_function_reward_types_exp(max_gens=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an animation\n",
    "Here the best evolved individual is selected and one episode is rendered. Make sure to save your lunar landers over time to track progress and make comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = []\n",
    "\n",
    "# gist to save gif from https://gist.github.com/botforge/64cbb71780e6208172bbf03cd9293553\n",
    "def save_frames_as_gif(frames, path='./', filename='evolved_lander.gif'):\n",
    "  plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "  patch = plt.imshow(frames[0])\n",
    "  plt.axis('off')\n",
    "  def animate(i):\n",
    "      patch.set_data(frames[i])\n",
    "  anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "  anim.save(path + filename, writer='imagemagick', fps=60)\n",
    "\n",
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "The coefficients in the multi-tree aren't optimised. Here Q-learning (taken from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) is used to optimise the weights further. Incorporate coefficient optimisation in training your agent(s). Coefficient Optimisation can be expensive. Think about how often you want to optimise, when, which individuals etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['((((x_4*x_5)*(x_3+x_4))/(x_1+(x_1/0.25225135684013367)))+(((x_5*x_3)-(x_3+x_1))/((x_1-x_4)-(x_4+4.020757675170898))))', '((((x_6-x_1)*(x_2--0.39643293619155884))+((x_4-x_2)/x_3))+((x_6-x_7)-((x_0+x_7)+x_7)))', '((((x_6*x_7)-(x_4*x_7))*(-4.199120044708252+(x_7/x_5)))-((x_5+(x_1-x_7))+x_5))', '((((x_4/x_3)*x_6)+((x_2*x_0)/(-2.1063617131441132+x_3)))/(((x_7/x_0)-(x_4+x_5))-(x_4+x_5)))']\n",
      "-1468.5912421090156\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "GAMMA = 0.99\n",
    "\n",
    "constants = best.get_subtrees_consts()\n",
    "\n",
    "if len(constants)>0:\n",
    "  optimizer = optim.AdamW(constants, lr=1e-3, amsgrad=True)\n",
    "\n",
    "for _ in range(500):\n",
    "\n",
    "  if len(constants)>0 and len(evo.memory)>batch_size:\n",
    "    target_tree = copy.deepcopy(best)\n",
    "\n",
    "    transitions = evo.memory.sample(batch_size)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                        batch.next_state)), dtype=torch.bool)\n",
    "\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                               if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = best.get_output_pt(state_batch).gather(1, action_batch)\n",
    "    next_state_values = torch.zeros(batch_size, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "      next_state_values[non_final_mask] = target_tree.get_output_pt(non_final_next_states).max(1)[0].float()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "   \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(constants, 100)\n",
    "    optimizer.step()\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAFCCAYAAABbz2zGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAALEwAACxMBAJqcGAAAF/dJREFUeJzt3VtsnPd9p/Hve5gTydFwhiOeRYqUeJJFmqQYHSq5jmRElaNGCZqk6QbYYLGLRYLF9rJArxZdLAp4e9ObFuhNepOijt3GdqLIiZs6CRSrRuNGlmLrZEuy7NgUJZHimUNyDm8vxqQpmZYli/zx9HyAwQxnhjN/vdDMw/fsBEEQCAAALCt3pQcAAMBGQHABADBAcAEAMEBwAQAwQHABADBAcAEAMODf60HHcazGAQDAmnevPW2ZwwUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwADBBQDAAMEFAMAAwQUAwIC/0gMAVkosJu3cWbxdKEg3b0q/+93Kjmm927mzON2DQJqdld58szjtgY3ACYIg+MQHHcdyLICplhbpH/+xeDufly5ckF59tfhzNiv9+tfSuXMrN7716Omnpe3bi8GdnJT++Z+L0zoIpFu3pBdeWOkRAg/nHkkluNi4WlqKAVho7tNQKEgffFCMQBBIU1PS3/+9dP78R89lzuzBPf10cbrPWfjtMzUlXbxYvJ3PS6dPF6f5wufe47sMWBUILrCIxYJ7t4WfjtnZYgiCQBobk556ShoYKD6Wy0nvvUcQPs3dwb3bwumXzxenuVScC/7pT6Xnniv+XChIg4PS+PjyjRX4LAgusIj7Ce69zH1ygqD4xf/Xfy39+MdLM7b16tOC+2nmpvnMjPTyy8VpPjKyJEMDlsS9gstGU8AD+KTPUj4vjY7ajmUj+KTpPbcOOJezHQ/wMAgucA93z8XOzHy0SPkv//KjRcr5vDQ8vHLjXC8WBnZmpjjNg6C4SPnFF6Uf/OCj501MFJ8DrBUEF1hg7gs/n5cuXy7uJhQEUiYjPfOM9NZbKzu+9WZhYMfGiluGS8Xp/+ab0ve/vzLjApYDwcWGtjCwr79eXC8oFRdVvvGGdOXKyo1tvZrb2nh8XPrud4sbRgVBcQnBz3++0qMDlg/BxYYVjbbqzJk/0lNPPaUgKK6DHRq69+/4rqsgCJRnc+TPpLb2H/TNb35L+XxBudxHSxCAjYDgYsNy3Zimpmruey62PBrVH7a26nYmo19eu6apbHZ5B7gOhcPbdOUK+zBjY+JYysB92lVbq1gopLpNm7S1vHylhwNgjSG4wH063d+vTDar/vFxXWPnz8+M/fuxUbFIGbhPw9PT+v6bb7IO9yHd68AAwFrk+74qKiqUTCbv/Tyj8QDrQo6VjwA+VFtbq66uLnV3d+vgwYM6cODAPZ9PcAEAeABHjx7VoUOH1N3drba2NtXW1t7XqhKCC3yK4gfJWXDtynEc5XKzklg8Cqxn4XBYZWVlqqur03e+8x0dOnRI1dXVKi0tVSgUeqDXIrjYcBzHlev68v2IfD+skpKkXNeT54WKFzck1/XkuK4815cfiikcKlE4VKJIuEyxWLlmc1P67Rs/0swMp6sB1qP29nY1NTVp7969+trXvqaOjo75xz7rhn8EF+taKtWoZHKLXMeV54fleb5cx5PnhtW6vVWV6Tbt7vmvioXLFY2UKxIqUzhUqrBfIt+LynFcSY4cuXIdX54Tluv6en/41zp/4accyxdYR9rb2/XYY4+pra1NBw4c0COPPKKysrIle32Ci3XLc8P6/c/9b8XLqrUpUqeQF5PvRuW6nhQ4qtkSVU0qpb2tNXIdvzhXqw8D67hy5C76l2wQBCqNVKi0tEKTk59yaCoAq5LjOPJ9X8lkUk8++aS+8pWvqLOzU+l0WvF4XK679HvNElysW1899LfalNyseKRWm8J18/fPRTQa8uW7EUVDiQd6XcdxFPWSqky36uZNzmYArCXpdFq1tbXq7u7Wl770JR05ckSxWGw+sMu5nzjBxbrluK5yhYxCbmzJP0SJkkbVVHXozfMnxIZTwOoWiUS0Z88edXd3a9++fdq3b58aGhrMD8JCcLGu5QoZ+W50yV836sdVEk0pGo1renpsyV8fwMNxHEetra366le/qkOHDqmpqUm1tbWKRpf+++B+EVysX0GgbGFGITe25C/tOK5iXkqpVIP6+99c8tdfzzi0I5ZDOBxWMplUXV2dDh8+rK9//etqbW1VJBKR7/ur4v8dwcW6lStMK+rEPtzSeOlVJXaqomIrwX1AHNoRS8XzPDU0NKijo0N9fX06ePCgdu3apXg8vtJDWxTBxbqVLWQU9yqW7fXjsVqVlKTk+xHlcuwfBFhJpVLav3+/Dh8+rK6uLrW0tKiqqmpZtixeSgQX61Jv+zfVWLNb08HIsr2HI1cl4QqVlaU1MvLBos9ggyrg4cViMUWjUfX19ekb3/iGHn/8caXTaZWVlcn3107G1s5IgQcQDpUqcAsKBaXL9h6O46ku1avL8V/eFVxHtTU7NT0zptu331229wfWs9LSUm3dulWtra36whe+oMOHD6upqWl+XexqWCf7oAgu1jzHcRUEHz+LTy6fUcR/sH1sH+h95Si9abtKYuVyHE9BkFcoFNOW+ke1r/vbOn/1xxofv6FsdnrZxgCsJ5FIRB0dHdq/f7927dqlzs5OdXZ2KhKJrPTQlgTBxZpXWdmiRKJGly+/okIhN39/tjClMq9m2d7XcRw58lVWUqlwuLhx1p7PfUsddX+oitIWxfyUBoeu6Hfvn1m2MQBrmed58jxPbW1tOnbs2PzuO3NHe1pvCC7WtES8Tnt7/pt8t0TVmx/Rxbf/pbgYNyhuNBVyS5b1/cNeieqqu3Xl2ityg5Ba6w4rEiqT70a0Od6hnh1/orHxGxodvb6s4wDWAsdxVFZWpsrKSm3ZskVHjhzRk08+qba2NoVCoeIfsWtwUfH9IrhYsyqT7Xps9/9SVUWHNpfs0FDibVWkmvSvv/wr5YNZFYKcPPfBTp/1oMJ+qcqiVZKkmZlxjd4ekFKBYqEKRbxNaq58XLfaLunf/+N7d8x9AxtJPB5Xe3u7ent75y/d3d1raoOnpbCx/rVYVyqSW5VMNigRaZAkOZ40OXJbU1MjyhdmF12vu9Qcx1PYL5HrepqcHtJPT/2F/uDA/1GuMK2GxAGVlzSqfctR3Ri8qKtXX1328awF63kOBh9xHEe9vb06evSo9u3bp61bt6q+vn5Jz76z1hBcrEmbSmv1+5/7U4X9MoW9Ms3mx3V74ppeP/es8vnZD88KtLxzt1Jx16CQH5PjeJKkscl+jY0NqLKiRYNTF5QuaVdd+S5tq39cY2M3NDh4ddnHtNpx4Iv1x3EclZaWatOmTWppadGxY8d09OhR1dXVraojPa00gos1qbnhgPLOrOKRWkmBRqd/p/OXf6zh0fclSa7jS0Gw7HO5juNIgSPfD8/f99KrfyHH+b9qbOzTxOwNxSM1enTrNzQ+NaDJySFlMqPLOibASnl5uVpaWrRz507t3r1b+/fv144dO+R53koPbVUiuFiTOjuOqTRUqbBXqtn8pN699W967/3TyuU/3AXHKUY3X5hVyFveDaccOQr5MS080MWvXv8bdbX9XCPT1xT1yxULJbWt5qCGRt7R5Su/MlncDSyHkpIS9fX16dChQ+rp6dG2bdu0bdu2FT0pwFpBcLGm+F5Uh/b+mXw/pES0QUFQ0I3xs+rvP6+hkXfufK4bUS6YXfYxuY6vSPjOqE9ND+lfTv0//d6u/6nh6Xe0uaRdTZWPaXjymkZG39etW1eWfVzAw3IcR5FIRNFoVL29vfryl7+sgwcPqqamRvF4fN3sH2uF4GJN6e34L6qv71JlySNyHU9jMx/o1shlvX7umY8913PDyhce7hjHQRAoUEFBkFchyCtQoXgd5BWoeF+2MKVYSVKO48yvnwyCgs689axq0l2q3dIxv2i5KX1Q048M6/SZf/qEw0ECK8t1XaVSKTU0NKi1tVVPPPGEnnjiCTU2Nq7pozytBgQXa8am0lrVVO9Q1C9X2I8rm5/WSOZdvXHhR4s+33PCyi8yhxsEBRWCnHKFnHIFV5Ozt1QIssoH2eJ14aPbhSCrIJj7gnH04dfNgp8dua6nIL/4mC9e+4m2N3xeozPvyncj8iKOSsOV8xtZAatFKpVSb2+v9u7dq66uLu3cuVPt7e3EdQndM7iRSES5XE75/Cd8mwCGyso2q2pzu+LhGjlyNTE7oLff/bk+GDj7secWCnkVgoJGMteUyd5WvjCjXDCjXH5a+SArR65m45u1bapNNyfPyXVC8uTLdUMqFPLyg7waYiGVe57Gp8f0y/cuazY7oZnZSc3MTmg2O/nhzxOayU5oaOSdRdfLvtN/Sv/0s2/rj4/8nd4d+ZVmM9N69bXvanj4PYtJturMzi7/In58Osdx5o/y9PnPf17Hjh3T7t27VVNTo3Q6zaLiZeIE99hGf3BwUC+88IKef/55Xbp0SQMDA5qcnLQcHyBJcl1f3/7jn2i6MKR0yQ6FvJiu3PxX/erXf6f+Gx8PruO42tv931We3CK34EvKy/Mc+X4gzyvI9fLyQnnJnVVmekwzs2Oanh3XzOyECkHxABX/Y8cOfautTU8e/5EmszndceafIPjwp/vbxaWyok3t2/5Ap889rYnJWw87OdYs3/c1OTmpmZmZj12mp6eVzWZXeojrlud5SiaTqqysVGdnp774xS/qyJEjSqVScl133R/laTW4Z3DnBEGgM2fO6JVXXtFrr72m3/zmNzp//rzF+ABJxYA+sfvPVV/brXA0pmw+o9++9bzO/PYHyhfunGtKpVLavHmzKioqtHnz5vlLVVWVampqVFVVpaqqKlVXV6u8vHxl/kEbVBAEGhkZ0fDwsIaHhzU0NKTbt29reHhYt2/f1u3btzU2NqbR0VENDw9rdHRUo6OjGhkZ0ejoqGZmOO/wg6qqqtKjjz6qnp4e9fb2qq+v746z7sDOfQV3oZGREV27dk3nzp3TiRMndOLECY2NjS3X+IB5vhdRVapDLY2H1Nz4ezr1xv9XfFOgxsZGNTU1qaGhQQ0NDUomkyorK1NZWZk2bdqkeDyuWCy26k9ODSmfzyuTySiTyWhqakpTU1PztzOZjEZGRjQwMKCBgQHduHFDN27c0PXr13Xjxg3dvHlzQyyy9jxPiURCiURC5eXlKi8v/9jtRCKhZDKpRCKhzZs3q6GhQTU1NQqFlv9gMPhkDxzcOYVCQTMzM8pkMvrhD3+oZ599Vm+88YZGRkZY7IzPxHEchcPhOy6RSESpVErNzc1qbW1Vc3OzWra3qbV1h2IlnlzXnV8XNXfhL/f1q1AofOySz+fnb9+8eVP9/f26fv263n//fX3wwQe6fv26+vv7NTAwoGw2q2w2q1wud8d1NptVobC0+0bf/f/S8zz5vr/o/WVlZUqlUkqlUkomk/O3y8vL77g/mUyqvLx8fhHw/V5jdfjMwV3M22+/rZdeekknT57UxYsXdeHCBeVyHLAdd3IcZ/6v8bkvlPLycqXTadXV1am+vl61tbWqr69XfX29EonlO6ctNo5cLqehoSENDg7q1q1bunXrlgYHBzU4OKibN29qeHhYExMTGh8fn79eeNvzPMViMUWjUUWj0XvejsVi80tXEomE4vH4/O25+xc+xpznxrCkwZ0zMTGhS5cu6dy5c/rZz36ml19+Wdevc3qyjcZ1XVVUVKiurk5btmyZD2ldXZ0qKirmF4PNBbe0tJTFvlgx2Wz2juDeHd+54M4dCOKTghuNRhUOh5mzxMcsS3DnBEGgsbExjY2N6dSpU/re976nU6dOaXp6esNu/OA4jkKhkEKhkHzfV2Njo/bs2aPdu3ert7dX8Xj8jsVddy/6Wuz6fm4/6O/e6/HFHkskEtq+fbtaWlrU1NSkbdu2qbm5WYlEQqFQSJFIROFwWKFQiC8jABvSsgZ3obm36e/v14kTJ3T8+HFduXJF165dUyaTsRjCigiFQqqoqFA6nVY6nVZDQ4O6urrU09Ojzs5OpdPplR7isiKsAFBkFty7ZbNZnTlzRq+//rpeffVVnTx5Ulevrv1Tl4XDYTU3N2vbtm1qaWlRc3OzGhoa1NjYqMbGRiWTyZUeIgBgBaxYcBcaHh7W9evXdfbsWT3//PM6fvy4stnsqj3C1dwO4q7ryvd99fT0qLu7Wz09PXr00UfnN4RIJBIqLS1d6eECAFaBVRHcOXOb9o+OjuqFF17Qc889tyqOcDW3xeHc1oVdXV3atWuXuru71d3drUgkcscm+CxGBQDcbVUF925BEOjs2bM6efKkXnvtNZ0+fdrkCFeJRGJ+MfCWLVvm9wHlvI8AgM9qVQd3odHRUV29elXnzp3Tiy++qBdffFGjo6NL8tqpVEqdnZ3q7u5WV1eXGhsblU6n5w8PyIG8AQAPa80Ed06hUND09LQymYyOHz+uZ555RmfPntXo6KimpqYW/R3Hce7YX66iokJ9fX3q6+vTnj171NTUNL+rTigUkudx6jQAwNJac8FdzOXLl/XSSy/pF7/4hS5duqS33npLyWRS1dXVqqqqUn19vTo6OtTR0aEdO3Zo69atrGcFAJhaF8GdMzk5qQsXLujixYtKpVKqqalRdXW1qqurCSwAYEWtq+ACALBaceBaAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAMEFwAAAwQXAAADBBcAAAM/Cd8NRkxVudfHAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames, filename='evolved_lander_RL.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander_RL.gif\" width=\"750\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
