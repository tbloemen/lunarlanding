{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving a Lunar Lander with differentiable Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "To install the required libraries run the command:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.229620Z",
     "start_time": "2025-06-05T12:03:34.225406Z"
    }
   },
   "source": [
    "# !pip install -r requirements.txt"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports from the standard genepro-multi library are done here. Any adjustments (e.g. different operators) should be made in the notebook. For example:\n",
    "\n",
    "```\n",
    "class SmoothOperator(Node):\n",
    "  def __init__(self):\n",
    "    super(SmoothOperator,self).__init__()\n",
    "    self.arity = 1\n",
    "    self.symb = \"SmoothOperator\"\n",
    "\n",
    "  def _get_args_repr(self, args):\n",
    "    return self._get_typical_repr(args,'before')\n",
    "\n",
    "  def get_output(self, X):\n",
    "    c_outs = self._get_child_outputs(X)\n",
    "    return np.smoothOperation(c_outs[0])\n",
    "\n",
    "  def get_output_pt(self, X):\n",
    "    c_outs = self._get_child_outputs_pt(X)\n",
    "    return torch.smoothOperation(c_outs[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.295245Z",
     "start_time": "2025-06-05T12:03:34.281375Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from genepro.node_impl import *\n",
    "from genepro.evo import Evolution\n",
    "from genepro.node_impl import Constant\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Setup\n",
    "Here we first setup the Gymnasium environment. Please see https://gymnasium.farama.org/environments/box2d/lunar_lander/ for more information on the environment. \n",
    "\n",
    "Then a memory buffer is made. This is a buffer in which state transitions are stored. When the buffer reaches its maximum capacity old transitions are replaced by new ones.\n",
    "\n",
    "A frame buffer is initialised, used to later store animation frames of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Wind\n",
    "\n",
    "Wind can be added to the current environment setup as below:\n",
    "\n",
    "```bash\n",
    "env = gym.make(\"LunarLander-v3\", continuous=False,\n",
    "               enable_wind=True, wind_power=15.0, turbulence_power=1.5)\n",
    "```\n",
    "\n",
    "Selin: When we add wind as a variable, it makes sense to also edit our fitness function. We can define a new boolean parameter (say have_random_wind) and if it is set to true when the fitness function is called, we can re-define the environment with a random wind value at each episode. This would potentially make our GP algorithm more robust to randomness. A possible implementation:\n",
    "\n",
    "```bash\n",
    "if use_random_wind:\n",
    "    env = gym.make(\"LunarLander-v3\", continuous=False,\n",
    "                    enable_wind=True,\n",
    "                    wind_power=np.random.uniform(5.0, 20.0),\n",
    "                    turbulence_power=np.random.uniform(0.5, 2.0))\n",
    "```\n",
    "\n",
    "The above can be added within the loop that goes over the episodes (the outer for loop of the fitness function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new Atomic Functions\n",
    "\n",
    "These atomic functions will be added as internal nodes within the Evolution setup.\n",
    "\n",
    "We can add min & max operators. Or instead, we can add **Clamp(x, min, max)** operator. This could be interesting.\n",
    "\n",
    "We can add domain specific operators:\n",
    "- Maybe a function that calculates the angle of the lunarlander to the pad (angle_to_pad(x_pos, y_pos)?)\n",
    "\n",
    "#### Fitness Calculation\n",
    "\n",
    "For the final fitness calculation, we are taking the sum of the rewards across episodes. Instead of sum operation, can we do this fitness calculation in a more clever way?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.362543Z",
     "start_time": "2025-06-05T12:03:34.348368Z"
    }
   },
   "source": [
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.413215Z",
     "start_time": "2025-06-05T12:03:34.406684Z"
    }
   },
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "      self.memory += other.memory\n",
    "      return self \n",
    "\n",
    "    def __add__(self, other):\n",
    "      self.memory = self.memory + other.memory \n",
    "      return self"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.474329Z",
     "start_time": "2025-06-05T12:03:34.466391Z"
    }
   },
   "source": [
    "frames = []"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function\n",
    "\n",
    "Here you get to be creative. The default setup evaluates 5 episodes of 300 frames. Think of what action to pick and what fitness function to use. The Multi-tree takes an input of $n \\times d$ where $n$ is a batch of size 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selin's Notes\n",
    "\n",
    "**Fitness Function:** Fitness is defined as the cumulative reward of the landing.\n",
    "\n",
    "**Multitree:** Multitree contains 4 trees, one for each action of the Lunar lander. \n",
    "\n",
    "- `0`: do nothing\n",
    "- `1`: fire left orientation engine\n",
    "- `2`: fire main engine\n",
    "- `3`: fire right orientation engine\n",
    "\n",
    "Multitree is initialized under genepro/variation.py file, with the generate_random_multitree() method. This method is called in the genepro/evo.py file within the _initialize_population() internal method. \n",
    "\n",
    "**Understanding the Input Sample:** Input sample is an 8-dimensional vector: [x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact]\n",
    "\n",
    "e.g. [-2.5, -2.5, -10, -10, -6.28, -10, 0, 0]\n",
    "\n",
    "- index0 : x position of the lander\n",
    "- index1: y position of the lander\n",
    "- index2: velocity in the x direction\n",
    "- index3: velocity in the y direction\n",
    "- index4: angle of the lander\n",
    "- index5: angular velocity\n",
    "- index6: leg 1 in contact\n",
    "- index7: leg 2 in contact\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.527113Z",
     "start_time": "2025-06-05T12:03:34.518554Z"
    }
   },
   "source": [
    "def make_fitness_function_pt(reduction='sum', has_wind=False):\n",
    "  '''\n",
    "  Generic fitness function factory\n",
    "  '''\n",
    "  def fitness_function(multitree, num_episodes=5, episode_duration=300, render=False, ignore_done=False):\n",
    "    memory = ReplayMemory(10000)\n",
    "    episode_returns = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "      rewards = []\n",
    "      # define a new environment with or without wind\n",
    "      if has_wind: \n",
    "        env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\",\n",
    "                        enable_wind=True,\n",
    "                        wind_power=np.random.uniform(0.0, 2.0), # TODO: Update the parameters for wind if necessary\n",
    "                        turbulence_power=np.random.uniform(0.0, 1.0)) # TODO: Update the parameters for turbulence if necessary\n",
    "      else:\n",
    "        env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "        \n",
    "      observation = env.reset()\n",
    "      observation = observation[0]\n",
    "      \n",
    "      for _ in range(episode_duration):\n",
    "        if render:\n",
    "          frames.append(env.render())\n",
    "\n",
    "        input_sample = torch.from_numpy(observation.reshape((1,-1))).float() # Input sample is a torch tensor\n",
    "\n",
    "        # what goes here? TODO\n",
    "        '''Below is Selin's possible definition of an action'''\n",
    "        output_scores = multitree.get_output_pt(input_sample) # A tensor of length 4, storing the scores of each action (after evaluating each tree)\n",
    "        action = torch.argmax(output_scores, dim=1) # Select the action with the highest score\n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        rewards.append(reward)\n",
    "        output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        memory.push(input_sample, torch.tensor([[action.item()]]), output_sample, torch.tensor([reward]))\n",
    "        if (terminated or truncated) and not ignore_done:\n",
    "          break\n",
    "      \n",
    "      # Store the sum of rewards for this episode\n",
    "      episode_returns.append(np.sum(rewards))\n",
    "          \n",
    "    # Define the reward types here\n",
    "    # TODO: Add more reward types!\n",
    "    if reduction == 'sum':\n",
    "      fitness = np.sum(episode_returns)\n",
    "    elif reduction == 'avg':\n",
    "      fitness = np.sum(episode_returns) / num_episodes\n",
    "    elif reduction == 'min':\n",
    "      fitness = np.min(episode_returns)\n",
    "    else:\n",
    "      raise ValueError(f\"Unknown reduction method: {reduction}\")\n",
    "    \n",
    "    return fitness, memory\n",
    "  \n",
    "  return fitness_function"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Setup\n",
    "Here the leaf and internal nodes are defined. Think about the odds of sampling a constant in this default configurations. Also think about any operators that could be useful and add them here. \n",
    "\n",
    "Adjust the population size (multiple of 8 if you want to use the standard tournament selection), max generations and max tree size to taste. Be aware that each of these settings can increase the runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selin's ideas about the things they wanted us to consider in the evolution setup (possible areas for improvement)\n",
    "\n",
    "In the below code, it says **Think about the probability of sampling a coefficient (which is basically a constant).** Currently, in the below code, we have 8 features and we are adding all of them as leaf nodes. \n",
    "\n",
    "However, we are only adding 1 constant as a leaf node. So this would give us a 1/9 chance of sampling a coefficient. This is a very small probability. Hence, **a possible area of improvement** might be to consider adding more constants (e.g. 4 or 5 constants) to our leaf nodes set and see how our GP performs. I think having constant is **important** because they allow the model to shift or scale features (e.g. x_4 + 1.5).\n",
    "\n",
    "**Having more operators:** Currently, we only have basic arithmetic operators. We can add the following non-linear operators:\n",
    "- log\n",
    "- sqrt\n",
    "- sin, cos\n",
    "- max, min\n",
    "- exp\n",
    "- square, cube, ...\n",
    "\n",
    "**Adjusting the parameters of the Evolution() method** called below. We can design an experiment to find the best combination of parameter values for population size, max generations, and max tree size."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.606910Z",
     "start_time": "2025-06-05T12:03:34.574547Z"
    }
   },
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [Constant()] # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [Plus(),Minus(),Times(),Div()] # Add your own operators here\n",
    "\n",
    "fitness_function_pt = make_fitness_function_pt(reduction='sum') # Baseline fitness function\n",
    "\n",
    "evo = Evolution(\n",
    "  fitness_function_pt, internal_nodes, leaf_nodes,\n",
    "  4,\n",
    "  pop_size=16,\n",
    "  max_gens=10,\n",
    "  max_tree_size=31,\n",
    "  n_jobs=8,\n",
    "  verbose=True)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'k'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 8\u001B[0m\n\u001B[1;32m      4\u001B[0m internal_nodes \u001B[38;5;241m=\u001B[39m [Plus(),Minus(),Times(),Div()] \u001B[38;5;66;03m# Add your own operators here\u001B[39;00m\n\u001B[1;32m      6\u001B[0m fitness_function_pt \u001B[38;5;241m=\u001B[39m make_fitness_function_pt(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# Baseline fitness function\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m evo \u001B[38;5;241m=\u001B[39m \u001B[43mEvolution\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m  \u001B[49m\u001B[43mfitness_function_pt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minternal_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mleaf_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m  \u001B[49m\u001B[43mpop_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m  \u001B[49m\u001B[43mmax_gens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m  \u001B[49m\u001B[43mmax_tree_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m31\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m  \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m  \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/lunarlanding/genepro/evo.py:127\u001B[0m, in \u001B[0;36mEvolution.__init__\u001B[0;34m(self, fitness_function, internal_nodes, leaf_nodes, n_trees, pop_size, init_max_depth, max_tree_size, crossovers, mutations, coeff_opts, selection, max_evals, max_gens, max_time, n_jobs, verbose)\u001B[0m\n\u001B[1;32m    125\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m50\u001B[39m):\n\u001B[0;32m--> 127\u001B[0m     k \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mpower(np\u001B[38;5;241m.\u001B[39me, \u001B[38;5;241m-\u001B[39mi\u001B[38;5;241m*\u001B[39m\u001B[43mcoeff_opts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mk\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[1;32m    128\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m12.5\u001B[39m\u001B[38;5;241m/\u001B[39mk\n\u001B[1;32m    129\u001B[0m coeff_opts \u001B[38;5;241m=\u001B[39m [{\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfun\u001B[39m\u001B[38;5;124m\"\u001B[39m: coeff_mutation,\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrate\u001B[39m\u001B[38;5;124m\"\u001B[39m: coeff_opts[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrate\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m     }\n\u001B[1;32m    137\u001B[0m }]\n",
      "\u001B[0;31mKeyError\u001B[0m: 'k'"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolve\n",
    "Running this cell will use all the settings above as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.626887395Z",
     "start_time": "2025-06-03T08:06:40.950047Z"
    }
   },
   "outputs": [],
   "source": [
    "best_fitnesses_across_gens = evo.evolve(is_multiobjective=False)\n",
    "\n",
    "# TODO: Should we account for the range difference between the two objectives? (diversity is in the range of 10s to 20s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best fitnesses across generations\n",
    "print(best_fitnesses_across_gens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.630742388Z",
     "start_time": "2025-06-05T10:31:55.991955Z"
    }
   },
   "source": [
    "def get_test_score(tree, has_wind=False):\n",
    "    rewards = []\n",
    "\n",
    "    for i in range(10):\n",
    "      # define a new environment with or without wind\n",
    "      if has_wind: \n",
    "        env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\",\n",
    "                        enable_wind=True,\n",
    "                        wind_power=np.random.uniform(0.0, 2.0), # TODO: Update the parameters for wind if necessary\n",
    "                        turbulence_power=np.random.uniform(0.0, 1.0)) # TODO: Update the parameters for turbulence if necessary\n",
    "      else:\n",
    "        env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "      observation = env.reset(seed=i)\n",
    "      observation = observation[0]\n",
    "\n",
    "      for _ in range(500):    \n",
    "        # build up the input sample for GP\n",
    "        input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        \n",
    "        # TODO: Again, define the action\n",
    "        '''Selin's idea of an action is added below'''\n",
    "        # get output (squeezing because it is encapsulated in an array)\n",
    "        output = tree.get_output_pt(input_sample)\n",
    "        action = torch.argmax(output, dim=1) # Select the action with the highest score\n",
    "        \n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        rewards.append(reward)\n",
    "        output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        if (terminated or truncated):\n",
    "            break\n",
    "\n",
    "    fitness = np.sum(rewards)\n",
    "    \n",
    "    return fitness\n",
    "\n",
    "best = evo.best_of_gens[-1]\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 37\u001B[0m\n\u001B[1;32m     33\u001B[0m     fitness \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(rewards)\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fitness\n\u001B[0;32m---> 37\u001B[0m best \u001B[38;5;241m=\u001B[39m \u001B[43mevo\u001B[49m\u001B[38;5;241m.\u001B[39mbest_of_gens[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28mprint\u001B[39m(best\u001B[38;5;241m.\u001B[39mget_readable_repr())\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(get_test_score(best))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'evo' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Experimentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down ideas for experimentation here!\n",
    "\n",
    "# TEST TYPE 1. Improving the Fitness Function\n",
    "'''\n",
    "Configuring the fitness function\n",
    "TEST 1.1 Single objective: Experiment with different quality metrics for fitness\n",
    "TEST 1.2 Multi-objective: Include diversity as a second metric\n",
    "\n",
    "Required additional arguments for fitness function: has_wind=False, reward_type='sum', is_multiobjective=False\n",
    "where reward_types = ['sum', 'min', 'weighted_sum']\n",
    "\n",
    "Wind Test \n",
    "Adding wind as a variable, and also adding a random wind value at each episode\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:49.902754Z",
     "start_time": "2025-06-05T12:03:49.893631Z"
    }
   },
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def write_results_to_csv(internal_nodes, leaf_nodes,\n",
    "                         pop_size, max_gens, max_tree_size,\n",
    "                         crossover_rate, mutation_rate, coeff_opt_rate, tournament_size,\n",
    "                         best_training, best_test, average_fitness, time_elapsed, num_evals, k = 0.2,\n",
    "                         filename=\"experiment_results_k.csv\"):\n",
    "\n",
    "    # Flatten node types to strings for logging\n",
    "    internal_str = \",\".join(type(node).__name__ for node in internal_nodes)\n",
    "    leaf_str = \",\".join(type(node).__name__ for node in leaf_nodes)\n",
    "\n",
    "    # Build a dictionary of all results/settings\n",
    "    row = {\n",
    "        \"internal_nodes\": internal_str,\n",
    "        \"leaf_nodes\": leaf_str,\n",
    "        \"pop_size\": pop_size,\n",
    "        \"max_gens\": max_gens,\n",
    "        \"max_tree_size\": max_tree_size,\n",
    "        \"crossover_rate\": crossover_rate,\n",
    "        \"mutation_rate\": mutation_rate,\n",
    "        \"coeff_opt_rate\": coeff_opt_rate,\n",
    "        \"k\": k,\n",
    "        \"tournament_size\": tournament_size,\n",
    "        \"best_training\": best_training,\n",
    "        \"best_test\": best_test,\n",
    "        \"average_fitness\": average_fitness,\n",
    "        \"time_elapsed\": time_elapsed,\n",
    "        \"num_evals\": num_evals\n",
    "    }\n",
    "\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=list(row.keys()))\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:52.421913Z",
     "start_time": "2025-06-05T12:03:52.414222Z"
    }
   },
   "source": [
    "from genepro.evo import subtree_crossover, subtree_mutation, coeff_mutation, tournament_selection\n",
    "\n",
    "# Hyperparameters in the baseline implementation which will be kept as is\n",
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [Constant()] # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [Plus(),Minus(),Times(),Div()] # Add your own operators here\n",
    "\n",
    "def main_experimentation_loop(fitness_function_version, internal_nodes, leaf_nodes,\n",
    "                                pop_size=64, max_gens=50, max_tree_size=31, k = 0.25,\n",
    "                                crossover_rate=0.875, mutation_rate=0.025, coeff_opt_rate=0.1, tournament_size=8,\n",
    "                                is_multiobjective=False):\n",
    "    \n",
    "    # Define the best-performing hyperparameters\n",
    "    crossovers = [{\"fun\": subtree_crossover, \"rate\": crossover_rate}]\n",
    "    mutations = [{\"fun\": subtree_mutation, \"rate\": mutation_rate}]\n",
    "    coeff_opts = [{\"fun\": coeff_mutation, \"rate\": coeff_opt_rate, \"k\": k}]\n",
    "    selection = {\"fun\": tournament_selection, \"kwargs\": {\"tournament_size\": tournament_size}}\n",
    "            \n",
    "    # Initialize an evolution setup with the correct fitness function\n",
    "    evo = Evolution(\n",
    "            fitness_function_version, \n",
    "            internal_nodes, \n",
    "            leaf_nodes,\n",
    "            n_trees=4, # Number of trees in multitree is fixed to 4\n",
    "            # resource settings\n",
    "            pop_size=pop_size,\n",
    "            max_gens=max_gens,\n",
    "            max_tree_size=max_tree_size,\n",
    "            # hyperparameter settings\n",
    "            crossovers=crossovers,\n",
    "            mutations=mutations,\n",
    "            coeff_opts=coeff_opts,\n",
    "            selection=selection,\n",
    "            n_jobs=8, # Number of jobs is fixed to 8 (used for parallel computing)\n",
    "            verbose=True)\n",
    "    \n",
    "    # Run the training loop for this evolution setup and get the fitnesses of the best individuals across generations\n",
    "    best_fitnesses_training, average_fitness, time_elapsed, num_evals = evo.evolve(is_multiobjective=is_multiobjective)\n",
    "\n",
    "    # Now, run the testing loop for this evolution setup and get the fitnesses of the best individuals across generations\n",
    "    # Extract best-of-generation trees\n",
    "    best_individuals = evo.best_of_gens\n",
    "\n",
    "    # Collect test scores for each best individual across generations\n",
    "    best_fitnesses_test = [\n",
    "        get_test_score(ind) for ind in best_individuals\n",
    "    ]\n",
    "\n",
    "    # Collect the average test score across the final population\n",
    "    final_population = evo.population\n",
    "    final_population_test_scores = [\n",
    "        get_test_score(ind) for ind in final_population\n",
    "    ]\n",
    "    average_fitness_test = np.mean(final_population_test_scores)\n",
    "\n",
    "    return best_fitnesses_training, best_fitnesses_test, average_fitness, average_fitness_test, time_elapsed, num_evals"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T08:44:07.030237Z",
     "start_time": "2025-06-05T12:49:45.173328Z"
    }
   },
   "source": [
    "# BASELINE TEST. Hyperparameter Testing\n",
    "\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "def hyperparameter_testing(max_gens=30):\n",
    "    crossover_rates = [0.875]\n",
    "    mutation_rates  = [0.025]\n",
    "    coeff_opt_rates = [0.1] # Coefficient mutation rate will be further optimized with improvements\n",
    "    tournament_sizes = [8]\n",
    "    k_opts = [0.01, 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "    total_runs = len(crossover_rates) * len(mutation_rates) * len(coeff_opt_rates) * len(tournament_sizes) * len(k_opts)\n",
    "    run_idx = 1\n",
    "\n",
    "    baseline_fitness_function = make_fitness_function_pt(reduction=\"sum\") # Test against the baseline fitness function: sum of rewards\n",
    "\n",
    "    for (cr, mr, cor, ts, k) in product(crossover_rates, mutation_rates, coeff_opt_rates, tournament_sizes, k_opts):\n",
    "        print(f\"\\n=== Run {run_idx}/{total_runs} | CR={cr} MR={mr} CoeffR={cor} TS={ts} K={k} ===\")\n",
    "        run_idx += 1\n",
    "        for i in range(3):\n",
    "\n",
    "            try:\n",
    "                best_training, best_test, average_fitness, average_fitness_test, time_elapsed, num_evals = main_experimentation_loop(\n",
    "                    fitness_function_version=baseline_fitness_function,\n",
    "                    internal_nodes=internal_nodes,\n",
    "                    leaf_nodes=leaf_nodes,\n",
    "                    crossover_rate=cr,\n",
    "                    mutation_rate=mr,\n",
    "                    max_gens=max_gens,\n",
    "                    k = k,\n",
    "                    coeff_opt_rate=cor,\n",
    "                    tournament_size=ts,\n",
    "                )\n",
    "\n",
    "                write_results_to_csv(\n",
    "                    internal_nodes=internal_nodes,\n",
    "                    leaf_nodes=leaf_nodes,\n",
    "                    pop_size=64,\n",
    "                    max_gens=30,\n",
    "                    max_tree_size=31,\n",
    "                    crossover_rate=cr,\n",
    "                    mutation_rate=mr,\n",
    "                    coeff_opt_rate=cor,\n",
    "                    k = k,\n",
    "                    tournament_size=ts,\n",
    "                    best_training=best_training,\n",
    "                    best_test=best_test,\n",
    "                    average_fitness=average_fitness,\n",
    "                    time_elapsed=time_elapsed,\n",
    "                    num_evals=num_evals\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in configuration CR={cr}, MR={mr}, CoeffR={cor}, TS={ts}: {e}\")\n",
    "                continue\n",
    "\n",
    "hyperparameter_testing(max_gens=50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/5 | CR=0.875 MR=0.025 CoeffR=0.1 TS=8 K=0.01 ===\n",
      "gen: 1, best of gen fitness: -469.402,\tbest of gen size: 27\n",
      "gen: 2, best of gen fitness: -458.640,\tbest of gen size: 27\n",
      "gen: 3, best of gen fitness: -128.289,\tbest of gen size: 23\n",
      "gen: 4, best of gen fitness: -253.036,\tbest of gen size: 15\n",
      "gen: 5, best of gen fitness: -327.041,\tbest of gen size: 27\n",
      "gen: 6, best of gen fitness: -229.010,\tbest of gen size: 15\n",
      "gen: 7, best of gen fitness: -274.210,\tbest of gen size: 15\n",
      "gen: 8, best of gen fitness: -189.846,\tbest of gen size: 15\n",
      "gen: 9, best of gen fitness: -139.365,\tbest of gen size: 15\n",
      "gen: 10, best of gen fitness: 48.555,\tbest of gen size: 15\n",
      "gen: 11, best of gen fitness: -62.879,\tbest of gen size: 15\n",
      "gen: 12, best of gen fitness: -210.716,\tbest of gen size: 21\n",
      "gen: 13, best of gen fitness: -87.954,\tbest of gen size: 13\n",
      "gen: 14, best of gen fitness: -121.527,\tbest of gen size: 21\n",
      "gen: 15, best of gen fitness: 48.838,\tbest of gen size: 13\n",
      "gen: 16, best of gen fitness: 14.128,\tbest of gen size: 17\n",
      "gen: 17, best of gen fitness: -91.770,\tbest of gen size: 27\n",
      "gen: 18, best of gen fitness: -153.036,\tbest of gen size: 21\n",
      "gen: 19, best of gen fitness: -66.762,\tbest of gen size: 17\n",
      "gen: 20, best of gen fitness: 3.183,\tbest of gen size: 27\n",
      "gen: 21, best of gen fitness: -122.455,\tbest of gen size: 21\n",
      "gen: 22, best of gen fitness: 3.781,\tbest of gen size: 21\n",
      "gen: 23, best of gen fitness: 23.472,\tbest of gen size: 21\n",
      "gen: 24, best of gen fitness: 119.087,\tbest of gen size: 13\n",
      "gen: 25, best of gen fitness: -56.426,\tbest of gen size: 21\n",
      "gen: 26, best of gen fitness: -3.375,\tbest of gen size: 19\n",
      "gen: 27, best of gen fitness: 142.674,\tbest of gen size: 21\n",
      "gen: 28, best of gen fitness: 24.704,\tbest of gen size: 27\n",
      "gen: 29, best of gen fitness: 260.338,\tbest of gen size: 17\n",
      "gen: 30, best of gen fitness: -1.233,\tbest of gen size: 25\n",
      "gen: 31, best of gen fitness: 105.298,\tbest of gen size: 13\n",
      "gen: 32, best of gen fitness: 128.798,\tbest of gen size: 21\n",
      "gen: 33, best of gen fitness: 407.158,\tbest of gen size: 13\n",
      "gen: 34, best of gen fitness: 188.826,\tbest of gen size: 13\n",
      "gen: 35, best of gen fitness: 417.158,\tbest of gen size: 13\n",
      "gen: 36, best of gen fitness: 376.409,\tbest of gen size: 13\n",
      "gen: 37, best of gen fitness: 429.514,\tbest of gen size: 13\n",
      "gen: 38, best of gen fitness: 504.527,\tbest of gen size: 13\n",
      "gen: 39, best of gen fitness: 402.356,\tbest of gen size: 13\n",
      "gen: 40, best of gen fitness: 479.992,\tbest of gen size: 13\n",
      "gen: 41, best of gen fitness: 351.665,\tbest of gen size: 13\n",
      "gen: 42, best of gen fitness: 692.239,\tbest of gen size: 13\n",
      "gen: 43, best of gen fitness: 492.971,\tbest of gen size: 13\n",
      "gen: 44, best of gen fitness: 385.003,\tbest of gen size: 13\n",
      "gen: 45, best of gen fitness: 429.115,\tbest of gen size: 13\n",
      "gen: 46, best of gen fitness: 364.062,\tbest of gen size: 13\n",
      "gen: 47, best of gen fitness: 563.729,\tbest of gen size: 13\n",
      "gen: 48, best of gen fitness: 542.999,\tbest of gen size: 13\n",
      "gen: 49, best of gen fitness: 527.756,\tbest of gen size: 13\n",
      "gen: 50, best of gen fitness: 754.311,\tbest of gen size: 13\n",
      "gen: 1, best of gen fitness: -466.137,\tbest of gen size: 25\n",
      "gen: 2, best of gen fitness: -331.859,\tbest of gen size: 25\n",
      "gen: 3, best of gen fitness: -291.377,\tbest of gen size: 25\n",
      "gen: 4, best of gen fitness: -190.696,\tbest of gen size: 25\n",
      "gen: 5, best of gen fitness: -140.594,\tbest of gen size: 25\n",
      "gen: 6, best of gen fitness: -83.796,\tbest of gen size: 25\n",
      "gen: 7, best of gen fitness: -185.000,\tbest of gen size: 25\n",
      "gen: 8, best of gen fitness: 28.052,\tbest of gen size: 31\n",
      "gen: 9, best of gen fitness: -143.681,\tbest of gen size: 25\n",
      "gen: 10, best of gen fitness: -115.314,\tbest of gen size: 31\n",
      "gen: 11, best of gen fitness: -55.308,\tbest of gen size: 25\n",
      "gen: 12, best of gen fitness: -237.331,\tbest of gen size: 29\n",
      "gen: 13, best of gen fitness: -254.943,\tbest of gen size: 25\n",
      "gen: 14, best of gen fitness: -223.366,\tbest of gen size: 29\n",
      "gen: 15, best of gen fitness: -94.512,\tbest of gen size: 25\n",
      "gen: 16, best of gen fitness: -182.068,\tbest of gen size: 25\n",
      "gen: 17, best of gen fitness: -195.420,\tbest of gen size: 29\n",
      "gen: 18, best of gen fitness: -93.605,\tbest of gen size: 25\n",
      "gen: 19, best of gen fitness: -209.917,\tbest of gen size: 29\n",
      "gen: 20, best of gen fitness: -161.652,\tbest of gen size: 25\n",
      "gen: 21, best of gen fitness: -220.862,\tbest of gen size: 29\n",
      "gen: 22, best of gen fitness: -162.159,\tbest of gen size: 25\n",
      "gen: 23, best of gen fitness: -187.153,\tbest of gen size: 25\n",
      "gen: 24, best of gen fitness: -11.845,\tbest of gen size: 25\n",
      "gen: 25, best of gen fitness: -150.260,\tbest of gen size: 25\n",
      "gen: 26, best of gen fitness: -173.482,\tbest of gen size: 29\n",
      "gen: 27, best of gen fitness: -118.622,\tbest of gen size: 25\n",
      "gen: 28, best of gen fitness: -220.891,\tbest of gen size: 25\n",
      "gen: 29, best of gen fitness: -195.437,\tbest of gen size: 31\n",
      "gen: 30, best of gen fitness: -94.153,\tbest of gen size: 29\n",
      "gen: 31, best of gen fitness: -138.387,\tbest of gen size: 29\n",
      "gen: 32, best of gen fitness: -154.038,\tbest of gen size: 25\n",
      "gen: 33, best of gen fitness: -207.820,\tbest of gen size: 29\n",
      "gen: 34, best of gen fitness: -16.864,\tbest of gen size: 29\n",
      "gen: 35, best of gen fitness: -122.760,\tbest of gen size: 25\n",
      "gen: 36, best of gen fitness: -151.806,\tbest of gen size: 29\n",
      "gen: 37, best of gen fitness: -147.120,\tbest of gen size: 25\n",
      "gen: 38, best of gen fitness: -14.312,\tbest of gen size: 29\n",
      "gen: 39, best of gen fitness: -79.161,\tbest of gen size: 25\n",
      "gen: 40, best of gen fitness: -62.464,\tbest of gen size: 29\n",
      "gen: 41, best of gen fitness: -73.944,\tbest of gen size: 29\n",
      "gen: 42, best of gen fitness: -70.770,\tbest of gen size: 27\n",
      "gen: 43, best of gen fitness: -175.252,\tbest of gen size: 29\n",
      "gen: 44, best of gen fitness: -167.103,\tbest of gen size: 29\n",
      "gen: 45, best of gen fitness: -101.593,\tbest of gen size: 31\n",
      "gen: 46, best of gen fitness: -69.572,\tbest of gen size: 29\n",
      "gen: 47, best of gen fitness: -164.370,\tbest of gen size: 29\n",
      "gen: 48, best of gen fitness: -100.708,\tbest of gen size: 29\n",
      "gen: 49, best of gen fitness: 27.774,\tbest of gen size: 29\n",
      "gen: 50, best of gen fitness: -201.775,\tbest of gen size: 29\n",
      "gen: 1, best of gen fitness: -492.610,\tbest of gen size: 29\n",
      "gen: 2, best of gen fitness: -276.750,\tbest of gen size: 27\n",
      "gen: 3, best of gen fitness: -451.137,\tbest of gen size: 25\n",
      "gen: 4, best of gen fitness: -426.736,\tbest of gen size: 25\n",
      "gen: 5, best of gen fitness: -424.351,\tbest of gen size: 25\n",
      "gen: 6, best of gen fitness: -360.437,\tbest of gen size: 25\n",
      "gen: 7, best of gen fitness: -385.668,\tbest of gen size: 23\n",
      "gen: 8, best of gen fitness: -436.870,\tbest of gen size: 25\n",
      "gen: 9, best of gen fitness: -454.520,\tbest of gen size: 25\n",
      "gen: 10, best of gen fitness: -225.638,\tbest of gen size: 25\n",
      "gen: 11, best of gen fitness: -343.936,\tbest of gen size: 23\n",
      "gen: 12, best of gen fitness: -353.424,\tbest of gen size: 25\n",
      "gen: 13, best of gen fitness: -315.569,\tbest of gen size: 29\n",
      "gen: 14, best of gen fitness: -454.125,\tbest of gen size: 23\n",
      "gen: 15, best of gen fitness: -433.658,\tbest of gen size: 25\n",
      "gen: 16, best of gen fitness: -328.720,\tbest of gen size: 25\n",
      "gen: 17, best of gen fitness: -287.177,\tbest of gen size: 23\n",
      "gen: 18, best of gen fitness: -259.876,\tbest of gen size: 25\n",
      "gen: 19, best of gen fitness: -380.649,\tbest of gen size: 25\n",
      "gen: 20, best of gen fitness: -359.889,\tbest of gen size: 31\n",
      "gen: 21, best of gen fitness: -350.427,\tbest of gen size: 31\n",
      "gen: 22, best of gen fitness: -267.052,\tbest of gen size: 25\n",
      "gen: 23, best of gen fitness: -260.256,\tbest of gen size: 25\n",
      "gen: 24, best of gen fitness: -249.502,\tbest of gen size: 25\n",
      "gen: 25, best of gen fitness: -221.986,\tbest of gen size: 27\n",
      "gen: 26, best of gen fitness: -255.287,\tbest of gen size: 25\n",
      "gen: 27, best of gen fitness: -235.481,\tbest of gen size: 25\n",
      "gen: 28, best of gen fitness: -245.697,\tbest of gen size: 23\n",
      "gen: 29, best of gen fitness: -224.657,\tbest of gen size: 25\n",
      "gen: 30, best of gen fitness: -276.012,\tbest of gen size: 21\n",
      "gen: 31, best of gen fitness: -19.177,\tbest of gen size: 31\n",
      "gen: 32, best of gen fitness: -216.253,\tbest of gen size: 29\n",
      "gen: 33, best of gen fitness: -209.762,\tbest of gen size: 25\n",
      "gen: 34, best of gen fitness: 75.873,\tbest of gen size: 29\n",
      "gen: 35, best of gen fitness: -139.242,\tbest of gen size: 29\n",
      "gen: 36, best of gen fitness: -118.408,\tbest of gen size: 29\n",
      "gen: 37, best of gen fitness: -82.651,\tbest of gen size: 29\n",
      "gen: 38, best of gen fitness: -30.863,\tbest of gen size: 29\n",
      "gen: 39, best of gen fitness: -184.586,\tbest of gen size: 29\n",
      "gen: 40, best of gen fitness: -18.042,\tbest of gen size: 29\n",
      "gen: 41, best of gen fitness: -111.231,\tbest of gen size: 29\n",
      "gen: 42, best of gen fitness: 59.659,\tbest of gen size: 29\n",
      "gen: 43, best of gen fitness: -162.475,\tbest of gen size: 29\n",
      "gen: 44, best of gen fitness: 175.240,\tbest of gen size: 31\n",
      "gen: 45, best of gen fitness: 48.816,\tbest of gen size: 31\n",
      "gen: 46, best of gen fitness: 159.750,\tbest of gen size: 31\n",
      "gen: 47, best of gen fitness: 66.799,\tbest of gen size: 31\n",
      "gen: 48, best of gen fitness: 256.618,\tbest of gen size: 31\n",
      "gen: 49, best of gen fitness: 199.305,\tbest of gen size: 31\n",
      "gen: 50, best of gen fitness: 158.341,\tbest of gen size: 31\n",
      "\n",
      "=== Run 2/5 | CR=0.875 MR=0.025 CoeffR=0.1 TS=8 K=0.05 ===\n",
      "gen: 1, best of gen fitness: -237.301,\tbest of gen size: 29\n",
      "gen: 2, best of gen fitness: -168.391,\tbest of gen size: 29\n",
      "gen: 3, best of gen fitness: -201.253,\tbest of gen size: 29\n",
      "gen: 4, best of gen fitness: 3.823,\tbest of gen size: 25\n",
      "gen: 5, best of gen fitness: -177.270,\tbest of gen size: 25\n",
      "gen: 6, best of gen fitness: -0.021,\tbest of gen size: 25\n",
      "gen: 7, best of gen fitness: -161.730,\tbest of gen size: 25\n",
      "gen: 8, best of gen fitness: -50.747,\tbest of gen size: 25\n",
      "gen: 9, best of gen fitness: -193.890,\tbest of gen size: 25\n",
      "gen: 10, best of gen fitness: 7.098,\tbest of gen size: 25\n",
      "gen: 11, best of gen fitness: 113.162,\tbest of gen size: 17\n",
      "gen: 12, best of gen fitness: -41.251,\tbest of gen size: 25\n",
      "gen: 13, best of gen fitness: 14.465,\tbest of gen size: 25\n",
      "gen: 14, best of gen fitness: 94.702,\tbest of gen size: 13\n",
      "gen: 15, best of gen fitness: -0.463,\tbest of gen size: 25\n",
      "gen: 16, best of gen fitness: 152.278,\tbest of gen size: 25\n",
      "gen: 17, best of gen fitness: 155.018,\tbest of gen size: 23\n",
      "gen: 18, best of gen fitness: 47.348,\tbest of gen size: 27\n",
      "gen: 19, best of gen fitness: 152.265,\tbest of gen size: 27\n",
      "gen: 20, best of gen fitness: 28.378,\tbest of gen size: 25\n",
      "gen: 21, best of gen fitness: 65.306,\tbest of gen size: 19\n",
      "gen: 22, best of gen fitness: 27.123,\tbest of gen size: 27\n",
      "gen: 23, best of gen fitness: 57.670,\tbest of gen size: 21\n",
      "gen: 24, best of gen fitness: 219.096,\tbest of gen size: 25\n",
      "gen: 25, best of gen fitness: 282.557,\tbest of gen size: 27\n",
      "gen: 26, best of gen fitness: 168.131,\tbest of gen size: 17\n",
      "gen: 27, best of gen fitness: 50.995,\tbest of gen size: 25\n",
      "gen: 28, best of gen fitness: -67.320,\tbest of gen size: 23\n",
      "gen: 29, best of gen fitness: 129.267,\tbest of gen size: 13\n",
      "gen: 30, best of gen fitness: 270.416,\tbest of gen size: 23\n",
      "gen: 31, best of gen fitness: -18.599,\tbest of gen size: 27\n",
      "gen: 32, best of gen fitness: 10.599,\tbest of gen size: 17\n",
      "gen: 33, best of gen fitness: 278.867,\tbest of gen size: 13\n",
      "gen: 34, best of gen fitness: 125.284,\tbest of gen size: 21\n",
      "gen: 35, best of gen fitness: 225.480,\tbest of gen size: 27\n",
      "gen: 36, best of gen fitness: 24.454,\tbest of gen size: 29\n",
      "gen: 37, best of gen fitness: 172.030,\tbest of gen size: 21\n",
      "gen: 38, best of gen fitness: 29.904,\tbest of gen size: 19\n",
      "gen: 39, best of gen fitness: 156.287,\tbest of gen size: 29\n",
      "gen: 40, best of gen fitness: 404.953,\tbest of gen size: 19\n",
      "gen: 41, best of gen fitness: 130.969,\tbest of gen size: 19\n",
      "gen: 42, best of gen fitness: 11.187,\tbest of gen size: 23\n",
      "gen: 43, best of gen fitness: 40.211,\tbest of gen size: 19\n",
      "gen: 44, best of gen fitness: 200.501,\tbest of gen size: 23\n",
      "gen: 45, best of gen fitness: 156.331,\tbest of gen size: 23\n",
      "gen: 46, best of gen fitness: 45.172,\tbest of gen size: 23\n",
      "gen: 47, best of gen fitness: 104.177,\tbest of gen size: 27\n",
      "gen: 48, best of gen fitness: -20.481,\tbest of gen size: 21\n",
      "gen: 49, best of gen fitness: 212.210,\tbest of gen size: 21\n",
      "gen: 50, best of gen fitness: 256.266,\tbest of gen size: 21\n",
      "gen: 1, best of gen fitness: -379.745,\tbest of gen size: 25\n",
      "gen: 2, best of gen fitness: -371.373,\tbest of gen size: 25\n",
      "gen: 3, best of gen fitness: -226.649,\tbest of gen size: 25\n",
      "gen: 4, best of gen fitness: -185.655,\tbest of gen size: 27\n",
      "gen: 5, best of gen fitness: -75.991,\tbest of gen size: 29\n",
      "gen: 6, best of gen fitness: -177.000,\tbest of gen size: 23\n",
      "gen: 7, best of gen fitness: 69.425,\tbest of gen size: 29\n",
      "gen: 8, best of gen fitness: -108.701,\tbest of gen size: 29\n",
      "gen: 9, best of gen fitness: -41.832,\tbest of gen size: 29\n",
      "gen: 10, best of gen fitness: -99.885,\tbest of gen size: 29\n",
      "gen: 11, best of gen fitness: 47.695,\tbest of gen size: 29\n",
      "gen: 12, best of gen fitness: -102.461,\tbest of gen size: 25\n",
      "gen: 13, best of gen fitness: -63.499,\tbest of gen size: 29\n",
      "gen: 14, best of gen fitness: -21.661,\tbest of gen size: 29\n",
      "gen: 15, best of gen fitness: -16.822,\tbest of gen size: 29\n",
      "gen: 16, best of gen fitness: 55.022,\tbest of gen size: 31\n",
      "gen: 17, best of gen fitness: 179.490,\tbest of gen size: 23\n",
      "gen: 18, best of gen fitness: 120.779,\tbest of gen size: 31\n",
      "gen: 19, best of gen fitness: 30.424,\tbest of gen size: 23\n",
      "gen: 20, best of gen fitness: 52.889,\tbest of gen size: 31\n",
      "gen: 21, best of gen fitness: 222.090,\tbest of gen size: 31\n",
      "gen: 22, best of gen fitness: 155.740,\tbest of gen size: 31\n",
      "gen: 23, best of gen fitness: 134.517,\tbest of gen size: 31\n",
      "gen: 24, best of gen fitness: 191.512,\tbest of gen size: 31\n",
      "gen: 25, best of gen fitness: 136.273,\tbest of gen size: 31\n",
      "gen: 26, best of gen fitness: 179.498,\tbest of gen size: 31\n",
      "gen: 27, best of gen fitness: 36.503,\tbest of gen size: 31\n",
      "gen: 28, best of gen fitness: 105.237,\tbest of gen size: 31\n",
      "gen: 29, best of gen fitness: 108.197,\tbest of gen size: 31\n",
      "gen: 30, best of gen fitness: 113.815,\tbest of gen size: 31\n",
      "gen: 31, best of gen fitness: 135.581,\tbest of gen size: 31\n",
      "gen: 32, best of gen fitness: 171.040,\tbest of gen size: 31\n",
      "gen: 33, best of gen fitness: 137.718,\tbest of gen size: 23\n",
      "gen: 34, best of gen fitness: 179.662,\tbest of gen size: 31\n",
      "gen: 35, best of gen fitness: 286.058,\tbest of gen size: 31\n",
      "gen: 36, best of gen fitness: 158.698,\tbest of gen size: 31\n",
      "gen: 37, best of gen fitness: 1.911,\tbest of gen size: 25\n",
      "gen: 38, best of gen fitness: 175.701,\tbest of gen size: 31\n",
      "gen: 39, best of gen fitness: 158.485,\tbest of gen size: 31\n",
      "gen: 40, best of gen fitness: 151.752,\tbest of gen size: 31\n",
      "gen: 41, best of gen fitness: 142.021,\tbest of gen size: 31\n",
      "gen: 42, best of gen fitness: 119.580,\tbest of gen size: 23\n",
      "gen: 43, best of gen fitness: 94.903,\tbest of gen size: 31\n",
      "gen: 44, best of gen fitness: 306.781,\tbest of gen size: 31\n",
      "gen: 45, best of gen fitness: 68.357,\tbest of gen size: 31\n",
      "gen: 46, best of gen fitness: 57.924,\tbest of gen size: 31\n",
      "gen: 47, best of gen fitness: 135.631,\tbest of gen size: 31\n",
      "gen: 48, best of gen fitness: 253.037,\tbest of gen size: 31\n",
      "gen: 49, best of gen fitness: 198.527,\tbest of gen size: 31\n",
      "gen: 50, best of gen fitness: 51.346,\tbest of gen size: 31\n",
      "gen: 1, best of gen fitness: -382.886,\tbest of gen size: 27\n",
      "gen: 2, best of gen fitness: -379.991,\tbest of gen size: 25\n",
      "gen: 3, best of gen fitness: -357.563,\tbest of gen size: 27\n",
      "gen: 4, best of gen fitness: -200.805,\tbest of gen size: 27\n",
      "gen: 5, best of gen fitness: -284.636,\tbest of gen size: 27\n",
      "gen: 6, best of gen fitness: -206.418,\tbest of gen size: 27\n",
      "gen: 7, best of gen fitness: -267.202,\tbest of gen size: 27\n",
      "gen: 8, best of gen fitness: -197.486,\tbest of gen size: 27\n",
      "gen: 9, best of gen fitness: -176.123,\tbest of gen size: 27\n",
      "gen: 10, best of gen fitness: -150.727,\tbest of gen size: 27\n",
      "gen: 11, best of gen fitness: -168.369,\tbest of gen size: 25\n",
      "gen: 12, best of gen fitness: -10.378,\tbest of gen size: 27\n",
      "gen: 13, best of gen fitness: -139.289,\tbest of gen size: 25\n",
      "gen: 14, best of gen fitness: -130.877,\tbest of gen size: 25\n",
      "gen: 15, best of gen fitness: -16.667,\tbest of gen size: 27\n",
      "gen: 16, best of gen fitness: -145.811,\tbest of gen size: 25\n",
      "gen: 17, best of gen fitness: -108.618,\tbest of gen size: 27\n",
      "gen: 18, best of gen fitness: -155.749,\tbest of gen size: 27\n",
      "gen: 19, best of gen fitness: -105.776,\tbest of gen size: 25\n",
      "gen: 20, best of gen fitness: -96.247,\tbest of gen size: 17\n",
      "gen: 21, best of gen fitness: -48.670,\tbest of gen size: 25\n",
      "gen: 22, best of gen fitness: 30.949,\tbest of gen size: 25\n",
      "gen: 23, best of gen fitness: 215.391,\tbest of gen size: 25\n",
      "gen: 24, best of gen fitness: 53.569,\tbest of gen size: 25\n",
      "gen: 25, best of gen fitness: 20.444,\tbest of gen size: 25\n",
      "gen: 26, best of gen fitness: 318.928,\tbest of gen size: 25\n",
      "gen: 27, best of gen fitness: 200.769,\tbest of gen size: 25\n",
      "gen: 28, best of gen fitness: 170.092,\tbest of gen size: 25\n",
      "gen: 29, best of gen fitness: 182.710,\tbest of gen size: 25\n",
      "gen: 30, best of gen fitness: 132.521,\tbest of gen size: 25\n",
      "gen: 31, best of gen fitness: 105.936,\tbest of gen size: 25\n",
      "gen: 32, best of gen fitness: 194.326,\tbest of gen size: 25\n",
      "gen: 33, best of gen fitness: 171.036,\tbest of gen size: 23\n",
      "gen: 34, best of gen fitness: 211.416,\tbest of gen size: 31\n",
      "gen: 35, best of gen fitness: 305.116,\tbest of gen size: 31\n",
      "gen: 36, best of gen fitness: 105.055,\tbest of gen size: 25\n",
      "gen: 37, best of gen fitness: 339.835,\tbest of gen size: 31\n",
      "gen: 38, best of gen fitness: 309.595,\tbest of gen size: 31\n",
      "gen: 39, best of gen fitness: 196.394,\tbest of gen size: 31\n",
      "gen: 40, best of gen fitness: 273.669,\tbest of gen size: 31\n",
      "gen: 41, best of gen fitness: 246.202,\tbest of gen size: 31\n",
      "gen: 42, best of gen fitness: 242.396,\tbest of gen size: 31\n",
      "gen: 43, best of gen fitness: 218.935,\tbest of gen size: 31\n",
      "gen: 44, best of gen fitness: 171.692,\tbest of gen size: 31\n",
      "gen: 45, best of gen fitness: 389.824,\tbest of gen size: 31\n",
      "gen: 46, best of gen fitness: 272.832,\tbest of gen size: 31\n",
      "gen: 47, best of gen fitness: 189.509,\tbest of gen size: 31\n",
      "gen: 48, best of gen fitness: 436.319,\tbest of gen size: 31\n",
      "gen: 49, best of gen fitness: 306.738,\tbest of gen size: 31\n",
      "gen: 50, best of gen fitness: 323.322,\tbest of gen size: 31\n",
      "\n",
      "=== Run 3/5 | CR=0.875 MR=0.025 CoeffR=0.1 TS=8 K=0.1 ===\n",
      "gen: 1, best of gen fitness: -406.466,\tbest of gen size: 25\n",
      "gen: 2, best of gen fitness: -344.507,\tbest of gen size: 29\n",
      "gen: 3, best of gen fitness: -376.644,\tbest of gen size: 31\n",
      "gen: 4, best of gen fitness: -395.527,\tbest of gen size: 31\n",
      "gen: 5, best of gen fitness: -375.493,\tbest of gen size: 21\n",
      "gen: 6, best of gen fitness: -106.893,\tbest of gen size: 21\n",
      "gen: 7, best of gen fitness: -383.070,\tbest of gen size: 31\n",
      "gen: 8, best of gen fitness: -316.120,\tbest of gen size: 31\n",
      "gen: 9, best of gen fitness: -351.038,\tbest of gen size: 31\n",
      "gen: 10, best of gen fitness: -374.800,\tbest of gen size: 31\n",
      "gen: 11, best of gen fitness: -351.603,\tbest of gen size: 21\n",
      "gen: 12, best of gen fitness: -346.457,\tbest of gen size: 21\n",
      "gen: 13, best of gen fitness: -302.536,\tbest of gen size: 21\n",
      "gen: 14, best of gen fitness: -317.714,\tbest of gen size: 23\n",
      "gen: 15, best of gen fitness: -308.701,\tbest of gen size: 29\n",
      "gen: 16, best of gen fitness: -292.604,\tbest of gen size: 21\n",
      "gen: 17, best of gen fitness: -338.394,\tbest of gen size: 23\n",
      "gen: 18, best of gen fitness: -311.024,\tbest of gen size: 23\n",
      "gen: 19, best of gen fitness: -341.668,\tbest of gen size: 23\n",
      "gen: 20, best of gen fitness: -308.497,\tbest of gen size: 27\n",
      "gen: 21, best of gen fitness: -318.225,\tbest of gen size: 23\n",
      "gen: 22, best of gen fitness: -320.195,\tbest of gen size: 29\n",
      "gen: 23, best of gen fitness: -12.599,\tbest of gen size: 29\n",
      "gen: 24, best of gen fitness: -267.447,\tbest of gen size: 23\n",
      "gen: 25, best of gen fitness: -296.884,\tbest of gen size: 23\n",
      "gen: 26, best of gen fitness: -290.565,\tbest of gen size: 29\n",
      "gen: 27, best of gen fitness: -324.722,\tbest of gen size: 29\n",
      "gen: 28, best of gen fitness: -318.488,\tbest of gen size: 29\n",
      "gen: 29, best of gen fitness: -337.649,\tbest of gen size: 21\n",
      "gen: 30, best of gen fitness: -321.878,\tbest of gen size: 23\n",
      "gen: 31, best of gen fitness: -307.848,\tbest of gen size: 29\n",
      "gen: 32, best of gen fitness: -221.020,\tbest of gen size: 29\n",
      "gen: 33, best of gen fitness: -232.568,\tbest of gen size: 25\n",
      "gen: 34, best of gen fitness: -274.433,\tbest of gen size: 25\n",
      "gen: 35, best of gen fitness: -236.579,\tbest of gen size: 29\n",
      "gen: 36, best of gen fitness: -216.660,\tbest of gen size: 29\n",
      "gen: 37, best of gen fitness: -173.232,\tbest of gen size: 29\n",
      "gen: 38, best of gen fitness: -128.827,\tbest of gen size: 29\n",
      "gen: 39, best of gen fitness: -109.475,\tbest of gen size: 29\n",
      "gen: 40, best of gen fitness: -22.455,\tbest of gen size: 29\n",
      "gen: 41, best of gen fitness: 33.736,\tbest of gen size: 29\n",
      "gen: 42, best of gen fitness: -19.643,\tbest of gen size: 29\n",
      "gen: 43, best of gen fitness: 112.504,\tbest of gen size: 29\n",
      "gen: 44, best of gen fitness: -87.963,\tbest of gen size: 29\n",
      "gen: 45, best of gen fitness: 174.457,\tbest of gen size: 29\n",
      "gen: 46, best of gen fitness: 26.222,\tbest of gen size: 29\n",
      "gen: 47, best of gen fitness: 59.251,\tbest of gen size: 27\n",
      "gen: 48, best of gen fitness: 7.287,\tbest of gen size: 25\n",
      "gen: 49, best of gen fitness: 170.149,\tbest of gen size: 31\n",
      "gen: 50, best of gen fitness: 54.783,\tbest of gen size: 25\n",
      "gen: 1, best of gen fitness: -417.838,\tbest of gen size: 27\n",
      "gen: 2, best of gen fitness: -527.853,\tbest of gen size: 27\n",
      "gen: 3, best of gen fitness: -517.470,\tbest of gen size: 21\n",
      "gen: 4, best of gen fitness: -327.009,\tbest of gen size: 25\n",
      "gen: 5, best of gen fitness: -394.064,\tbest of gen size: 21\n",
      "gen: 6, best of gen fitness: -358.199,\tbest of gen size: 21\n",
      "gen: 7, best of gen fitness: -402.539,\tbest of gen size: 25\n",
      "gen: 8, best of gen fitness: -260.564,\tbest of gen size: 29\n",
      "gen: 9, best of gen fitness: -320.463,\tbest of gen size: 27\n",
      "gen: 10, best of gen fitness: -307.195,\tbest of gen size: 23\n",
      "gen: 11, best of gen fitness: -308.843,\tbest of gen size: 29\n",
      "gen: 12, best of gen fitness: -359.289,\tbest of gen size: 27\n",
      "gen: 13, best of gen fitness: -259.714,\tbest of gen size: 29\n",
      "gen: 14, best of gen fitness: -62.614,\tbest of gen size: 27\n",
      "gen: 15, best of gen fitness: -54.477,\tbest of gen size: 27\n",
      "gen: 16, best of gen fitness: -6.216,\tbest of gen size: 27\n",
      "gen: 17, best of gen fitness: -77.181,\tbest of gen size: 27\n",
      "gen: 18, best of gen fitness: -137.274,\tbest of gen size: 27\n",
      "gen: 19, best of gen fitness: 36.368,\tbest of gen size: 27\n",
      "gen: 20, best of gen fitness: -45.415,\tbest of gen size: 27\n",
      "gen: 21, best of gen fitness: -146.104,\tbest of gen size: 27\n",
      "gen: 22, best of gen fitness: -45.761,\tbest of gen size: 27\n",
      "gen: 23, best of gen fitness: 7.656,\tbest of gen size: 27\n",
      "gen: 24, best of gen fitness: -34.148,\tbest of gen size: 19\n",
      "gen: 25, best of gen fitness: 4.078,\tbest of gen size: 27\n",
      "gen: 26, best of gen fitness: -85.028,\tbest of gen size: 19\n",
      "gen: 27, best of gen fitness: -99.183,\tbest of gen size: 27\n",
      "gen: 28, best of gen fitness: 32.969,\tbest of gen size: 27\n",
      "gen: 29, best of gen fitness: 10.090,\tbest of gen size: 27\n",
      "gen: 30, best of gen fitness: -69.679,\tbest of gen size: 19\n",
      "gen: 31, best of gen fitness: 146.722,\tbest of gen size: 29\n",
      "gen: 32, best of gen fitness: -72.716,\tbest of gen size: 29\n",
      "gen: 33, best of gen fitness: 83.439,\tbest of gen size: 27\n",
      "gen: 34, best of gen fitness: 92.121,\tbest of gen size: 27\n",
      "gen: 35, best of gen fitness: 150.781,\tbest of gen size: 19\n",
      "gen: 36, best of gen fitness: 43.316,\tbest of gen size: 27\n",
      "gen: 37, best of gen fitness: 270.427,\tbest of gen size: 19\n",
      "gen: 38, best of gen fitness: 105.967,\tbest of gen size: 29\n",
      "gen: 39, best of gen fitness: 102.679,\tbest of gen size: 27\n",
      "gen: 40, best of gen fitness: 87.178,\tbest of gen size: 29\n",
      "gen: 41, best of gen fitness: 114.573,\tbest of gen size: 27\n",
      "gen: 42, best of gen fitness: 104.979,\tbest of gen size: 27\n",
      "gen: 43, best of gen fitness: 27.863,\tbest of gen size: 29\n",
      "gen: 44, best of gen fitness: 156.041,\tbest of gen size: 27\n",
      "gen: 45, best of gen fitness: 159.504,\tbest of gen size: 29\n",
      "gen: 46, best of gen fitness: 284.213,\tbest of gen size: 31\n",
      "gen: 47, best of gen fitness: 119.273,\tbest of gen size: 29\n",
      "gen: 48, best of gen fitness: 184.552,\tbest of gen size: 29\n",
      "gen: 49, best of gen fitness: 265.878,\tbest of gen size: 31\n",
      "gen: 50, best of gen fitness: 312.003,\tbest of gen size: 29\n",
      "gen: 1, best of gen fitness: -454.895,\tbest of gen size: 27\n",
      "gen: 2, best of gen fitness: -451.886,\tbest of gen size: 29\n",
      "gen: 3, best of gen fitness: -382.106,\tbest of gen size: 27\n",
      "gen: 4, best of gen fitness: -429.858,\tbest of gen size: 27\n",
      "gen: 5, best of gen fitness: -373.836,\tbest of gen size: 27\n",
      "gen: 6, best of gen fitness: -353.348,\tbest of gen size: 27\n",
      "gen: 7, best of gen fitness: -410.071,\tbest of gen size: 23\n",
      "gen: 8, best of gen fitness: -361.009,\tbest of gen size: 27\n",
      "gen: 9, best of gen fitness: -331.973,\tbest of gen size: 29\n",
      "gen: 10, best of gen fitness: -357.398,\tbest of gen size: 31\n",
      "gen: 11, best of gen fitness: -253.016,\tbest of gen size: 31\n",
      "gen: 12, best of gen fitness: -327.053,\tbest of gen size: 31\n",
      "gen: 13, best of gen fitness: -255.967,\tbest of gen size: 23\n",
      "gen: 14, best of gen fitness: -305.855,\tbest of gen size: 23\n",
      "gen: 15, best of gen fitness: -296.115,\tbest of gen size: 31\n",
      "gen: 16, best of gen fitness: -270.202,\tbest of gen size: 31\n",
      "gen: 17, best of gen fitness: -295.066,\tbest of gen size: 23\n",
      "gen: 18, best of gen fitness: -284.922,\tbest of gen size: 31\n",
      "gen: 19, best of gen fitness: -273.493,\tbest of gen size: 31\n",
      "gen: 20, best of gen fitness: -290.857,\tbest of gen size: 31\n",
      "gen: 21, best of gen fitness: -285.021,\tbest of gen size: 25\n",
      "gen: 22, best of gen fitness: -238.820,\tbest of gen size: 31\n",
      "gen: 23, best of gen fitness: -317.356,\tbest of gen size: 31\n",
      "gen: 24, best of gen fitness: -305.364,\tbest of gen size: 31\n",
      "gen: 25, best of gen fitness: -297.049,\tbest of gen size: 31\n",
      "gen: 26, best of gen fitness: -275.033,\tbest of gen size: 31\n",
      "gen: 27, best of gen fitness: -193.430,\tbest of gen size: 31\n",
      "gen: 28, best of gen fitness: -230.529,\tbest of gen size: 31\n",
      "gen: 29, best of gen fitness: -176.148,\tbest of gen size: 31\n",
      "gen: 30, best of gen fitness: -254.504,\tbest of gen size: 31\n",
      "gen: 31, best of gen fitness: -146.993,\tbest of gen size: 31\n",
      "gen: 32, best of gen fitness: -186.587,\tbest of gen size: 31\n",
      "gen: 33, best of gen fitness: -152.164,\tbest of gen size: 31\n",
      "gen: 34, best of gen fitness: -234.143,\tbest of gen size: 31\n",
      "gen: 35, best of gen fitness: -183.585,\tbest of gen size: 31\n",
      "gen: 36, best of gen fitness: -191.054,\tbest of gen size: 31\n",
      "gen: 37, best of gen fitness: -24.850,\tbest of gen size: 23\n",
      "gen: 38, best of gen fitness: -188.676,\tbest of gen size: 31\n",
      "gen: 39, best of gen fitness: -238.482,\tbest of gen size: 31\n",
      "gen: 40, best of gen fitness: -171.638,\tbest of gen size: 29\n",
      "gen: 41, best of gen fitness: -165.933,\tbest of gen size: 31\n",
      "gen: 42, best of gen fitness: -154.763,\tbest of gen size: 31\n",
      "gen: 43, best of gen fitness: -128.954,\tbest of gen size: 31\n",
      "gen: 44, best of gen fitness: -187.409,\tbest of gen size: 31\n",
      "gen: 45, best of gen fitness: -83.207,\tbest of gen size: 31\n",
      "gen: 46, best of gen fitness: -154.918,\tbest of gen size: 31\n",
      "gen: 47, best of gen fitness: -110.013,\tbest of gen size: 31\n",
      "gen: 48, best of gen fitness: -108.884,\tbest of gen size: 29\n",
      "gen: 49, best of gen fitness: -201.717,\tbest of gen size: 31\n",
      "gen: 50, best of gen fitness: -87.532,\tbest of gen size: 31\n",
      "\n",
      "=== Run 4/5 | CR=0.875 MR=0.025 CoeffR=0.1 TS=8 K=0.15 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 58\u001B[0m\n\u001B[1;32m     55\u001B[0m                 \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError in configuration CR=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, MR=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, CoeffR=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcor\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, TS=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mts\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     56\u001B[0m                 \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m---> 58\u001B[0m \u001B[43mhyperparameter_testing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_gens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[34], line 24\u001B[0m, in \u001B[0;36mhyperparameter_testing\u001B[0;34m(max_gens)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m):\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 24\u001B[0m         best_training, best_test, average_fitness, average_fitness_test, time_elapsed, num_evals \u001B[38;5;241m=\u001B[39m \u001B[43mmain_experimentation_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfitness_function_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbaseline_fitness_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m            \u001B[49m\u001B[43minternal_nodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minternal_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m            \u001B[49m\u001B[43mleaf_nodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mleaf_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcrossover_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmutation_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_gens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_gens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m            \u001B[49m\u001B[43mk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcoeff_opt_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtournament_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m         write_results_to_csv(\n\u001B[1;32m     37\u001B[0m             internal_nodes\u001B[38;5;241m=\u001B[39minternal_nodes,\n\u001B[1;32m     38\u001B[0m             leaf_nodes\u001B[38;5;241m=\u001B[39mleaf_nodes,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     51\u001B[0m             num_evals\u001B[38;5;241m=\u001B[39mnum_evals\n\u001B[1;32m     52\u001B[0m         )\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "Cell \u001B[0;32mIn[31], line 39\u001B[0m, in \u001B[0;36mmain_experimentation_loop\u001B[0;34m(fitness_function_version, internal_nodes, leaf_nodes, pop_size, max_gens, max_tree_size, k, crossover_rate, mutation_rate, coeff_opt_rate, tournament_size, is_multiobjective)\u001B[0m\n\u001B[1;32m     21\u001B[0m evo \u001B[38;5;241m=\u001B[39m Evolution(\n\u001B[1;32m     22\u001B[0m         fitness_function_version, \n\u001B[1;32m     23\u001B[0m         internal_nodes, \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     35\u001B[0m         n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, \u001B[38;5;66;03m# Number of jobs is fixed to 8 (used for parallel computing)\u001B[39;00m\n\u001B[1;32m     36\u001B[0m         verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# Run the training loop for this evolution setup and get the fitnesses of the best individuals across generations\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m best_fitnesses_training, average_fitness, time_elapsed, num_evals \u001B[38;5;241m=\u001B[39m \u001B[43mevo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mis_multiobjective\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_multiobjective\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Now, run the testing loop for this evolution setup and get the fitnesses of the best individuals across generations\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# Extract best-of-generation trees\u001B[39;00m\n\u001B[1;32m     43\u001B[0m best_individuals \u001B[38;5;241m=\u001B[39m evo\u001B[38;5;241m.\u001B[39mbest_of_gens\n",
      "File \u001B[0;32m~/PycharmProjects/lunarlanding/genepro/evo.py:311\u001B[0m, in \u001B[0;36mEvolution.evolve\u001B[0;34m(self, is_multiobjective)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;66;03m# generational loop\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_must_terminate():\n\u001B[1;32m    310\u001B[0m   \u001B[38;5;66;03m# perform one generation\u001B[39;00m\n\u001B[0;32m--> 311\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_perform_generation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mis_multiobjective\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    312\u001B[0m   \u001B[38;5;66;03m# log info\u001B[39;00m\n\u001B[1;32m    313\u001B[0m   best_fitnesses_across_gens\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_of_gens[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mfitness)\n",
      "File \u001B[0;32m~/PycharmProjects/lunarlanding/genepro/evo.py:253\u001B[0m, in \u001B[0;36mEvolution._perform_generation\u001B[0;34m(self, is_multiobjective)\u001B[0m\n\u001B[1;32m    250\u001B[0m   parents \u001B[38;5;241m=\u001B[39m [ind\u001B[38;5;241m.\u001B[39mreference \u001B[38;5;28;01mfor\u001B[39;00m ind \u001B[38;5;129;01min\u001B[39;00m selected]\n\u001B[1;32m    252\u001B[0m \u001B[38;5;66;03m# generate offspring\u001B[39;00m\n\u001B[0;32m--> 253\u001B[0m offspring_population \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerate_offspring\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m  \u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcrossovers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmutations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_opts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m  \u001B[49m\u001B[43mparents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minternal_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mleaf_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m  \u001B[49m\u001B[43mconstraints\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tree_size\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_tree_size\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mparents\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;66;03m# evaluate each offspring and store its fitness \u001B[39;00m\n\u001B[1;32m    260\u001B[0m fitnesses \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)(delayed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfitness_function)(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m offspring_population)\n",
      "File \u001B[0;32m~/PycharmProjects/lunarlanding/.venv1/lib/python3.10/site-packages/joblib/parallel.py:2072\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   2066\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   2067\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   2068\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[1;32m   2069\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   2070\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 2072\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/lunarlanding/.venv1/lib/python3.10/site-packages/joblib/parallel.py:1682\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1679\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m   1681\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1682\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1684\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1685\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1686\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1687\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[1;32m   1688\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/lunarlanding/.venv1/lib/python3.10/site-packages/joblib/parallel.py:1800\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1789\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_ordered:\n\u001B[1;32m   1790\u001B[0m     \u001B[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001B[39;00m\n\u001B[1;32m   1791\u001B[0m     \u001B[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1795\u001B[0m     \u001B[38;5;66;03m# control only have to be done on the amount of time the next\u001B[39;00m\n\u001B[1;32m   1796\u001B[0m     \u001B[38;5;66;03m# dispatched job is pending.\u001B[39;00m\n\u001B[1;32m   1797\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (nb_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   1798\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING\n\u001B[1;32m   1799\u001B[0m     ):\n\u001B[0;32m-> 1800\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1801\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m   1803\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m nb_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1804\u001B[0m     \u001B[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001B[39;00m\n\u001B[1;32m   1805\u001B[0m     \u001B[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1811\u001B[0m     \u001B[38;5;66;03m# timeouts before any other dispatched job has completed and\u001B[39;00m\n\u001B[1;32m   1812\u001B[0m     \u001B[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST TYPE 1. Improving the Fitness Function\n",
    "'''\n",
    "Configuring the fitness function\n",
    "TEST 1.1 Single objective: Experiment with different quality metrics for fitness\n",
    "TEST 1.2 Multi-objective: Include diversity as a second metric\n",
    "\n",
    "Required additional arguments for fitness function: has_wind=False, reward_type='sum', is_multiobjective=False\n",
    "where reward_types = ['sum', 'min', 'weighted_sum']\n",
    "\n",
    "Wind Test \n",
    "Adding wind as a variable, and also adding a random wind value at each episode\n",
    "''' \n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def write_results_to_csv_fitness_improvement(internal_nodes, leaf_nodes,\n",
    "                                            has_wind, reward_type,\n",
    "                                            pop_size, max_gens,\n",
    "                                            best_training, best_test, average_fitness, time_elapsed, num_evals):\n",
    "\n",
    "    # Flatten node types to strings for logging\n",
    "    internal_str = \",\".join(type(node).__name__ for node in internal_nodes)\n",
    "    leaf_str = \",\".join(type(node).__name__ for node in leaf_nodes)\n",
    "\n",
    "    # Build a dictionary of all results/settings\n",
    "    row = {\n",
    "        \"internal_nodes\": internal_str,\n",
    "        \"leaf_nodes\": leaf_str,\n",
    "        \"has_wind\": has_wind,\n",
    "        \"reward_type\": reward_type,\n",
    "        \"pop_size\": pop_size,\n",
    "        \"max_gens\": max_gens,\n",
    "        \"best_training\": best_training,\n",
    "        \"best_test\": best_test,\n",
    "        \"average_fitness\": average_fitness,\n",
    "        \"time_elapsed\": time_elapsed,\n",
    "        \"num_evals\": num_evals\n",
    "    }\n",
    "\n",
    "    name = \"fitness_comp_improvement.csv\"\n",
    "    if has_wind:\n",
    "        name = \"fitness_comp_improvement_with_wind.csv\"\n",
    "\n",
    "    os.makedirs(\"improvement_results\", exist_ok=True)\n",
    "    filename = os.path.join(\"improvement_results\", name)\n",
    "    \n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=list(row.keys()))\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "def fitness_function_reward_types_exp(max_gens=30, has_wind=False):\n",
    "    reward_types = ['avg', 'min'] # Use average instead of sum for comparison purposes\n",
    "\n",
    "    for _ in range(3): # Run the experiment for 3 times for each reward type (to account for randomness)\n",
    "        for reward_type in reward_types:\n",
    "            fitness_function_version = make_fitness_function_pt(reduction=reward_type, has_wind=has_wind)\n",
    "            print(f\"\\nRunning experiment for reward type: {reward_type}\")\n",
    "            best_training, best_test, average_fitness, average_fitness_test, \\\n",
    "                time_elapsed, num_evals = main_experimentation_loop(fitness_function_version,\n",
    "                                                                    internal_nodes, \n",
    "                                                                    leaf_nodes,\n",
    "                                                                    pop_size=64,\n",
    "                                                                    max_gens=max_gens, \n",
    "                                                                    max_tree_size=31)\n",
    "            print(f\"Best training fitness: {best_training}, Best test fitness: {best_test}, Average fitness: {average_fitness}, Average test fitness: {average_fitness_test}, Time elapsed: {time_elapsed}, Number of evaluations: {num_evals}\")\n",
    "            write_results_to_csv_fitness_improvement(\n",
    "                internal_nodes=internal_nodes,\n",
    "                leaf_nodes=leaf_nodes,\n",
    "                has_wind=has_wind,\n",
    "                reward_type=reward_type,\n",
    "                pop_size=64,\n",
    "                max_gens=max_gens,\n",
    "                best_training=best_training,\n",
    "                best_test=best_test,\n",
    "                average_fitness=average_fitness,\n",
    "                time_elapsed=time_elapsed,\n",
    "                num_evals=num_evals\n",
    "            )\n",
    "        \n",
    "fitness_function_reward_types_exp(max_gens=50, has_wind=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_and_average_per_generation(csv_path, plot_type=\"Best\"):\n",
    "    '''\n",
    "    Method for averaging fitness values per generation across different experiment runs\n",
    "    '''\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    column_name = 'best_training'\n",
    "    if plot_type == \"Average\":\n",
    "        column_name = 'average_fitness'\n",
    "\n",
    "    df[column_name] = df[column_name].apply(lambda s: eval(s, {\"np\": np}))\n",
    "    df['best_test'] = df['best_test'].apply(lambda s: eval(s, {\"np\": np}))\n",
    "\n",
    "    training_dict = defaultdict(list)  \n",
    "    test_dict = defaultdict(list)     \n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        training_dict[row['reward_type']].append(row[column_name])\n",
    "        test_dict[row['reward_type']].append(row['best_test'])\n",
    "\n",
    "    # Average across runs for each generation\n",
    "    averaged_training = []\n",
    "    averaged_test = []\n",
    "    reward_types = []\n",
    "\n",
    "    for reward_type in sorted(training_dict.keys()):\n",
    "        reward_types.append(reward_type)\n",
    "\n",
    "        train_runs = np.array(training_dict[reward_type])  \n",
    "        test_runs = np.array(test_dict[reward_type])\n",
    "\n",
    "        avg_train = np.mean(train_runs, axis=0).tolist()\n",
    "        avg_test = np.mean(test_runs, axis=0).tolist()\n",
    "\n",
    "        averaged_training.append(avg_train)\n",
    "        averaged_test.append(avg_test)\n",
    "\n",
    "    return averaged_training, averaged_test, reward_types\n",
    "\n",
    "\n",
    "def plot_fitnesses_reward_types_exp(training_fitnesses, test_fitnesses, reward_types, plot_type=\"Best\", has_wind=False):\n",
    "    print(\"Training fitnesses:\", training_fitnesses)\n",
    "    print(\"Test fitnesses:\", test_fitnesses)\n",
    "    generations = list(range(len(training_fitnesses[0])))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Training fitness plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, reward_type in enumerate(reward_types):\n",
    "        plt.plot(generations, training_fitnesses[i], label=reward_type)\n",
    "    title_train = f\"{plot_type} Training Fitness over Generations {'with Wind' if has_wind else 'without Wind'}\"\n",
    "    plt.title(title_train)\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    if plot_type == \"Best\":\n",
    "        # Testing fitness plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for i, reward_type in enumerate(reward_types):\n",
    "            plt.plot(generations, test_fitnesses[i], label=reward_type)\n",
    "        title_test = f\"{plot_type} Testing Fitness over Generations {'with Wind' if has_wind else 'without Wind'}\"\n",
    "        plt.title(title_test)\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Fitness\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "csv_path = \"improvement_results/fitness_comp_improvement_with_wind.csv\"  # or without wind\n",
    "training_avg, test_avg, reward_types = load_and_average_per_generation(csv_path, plot_type=\"Best\")\n",
    "plot_fitnesses_reward_types_exp(training_avg, test_avg, reward_types, plot_type=\"Best\", has_wind=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST TYPE 2. Testing the Multiobjective Fitness Function\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def write_results_to_csv_multiobjective(internal_nodes, leaf_nodes,\n",
    "                                            has_wind, reward_type, is_multiobjective,\n",
    "                                            pop_size, max_gens,\n",
    "                                            best_training, best_test, average_fitness, time_elapsed, num_evals):\n",
    "\n",
    "    # Flatten node types to strings for logging\n",
    "    internal_str = \",\".join(type(node).__name__ for node in internal_nodes)\n",
    "    leaf_str = \",\".join(type(node).__name__ for node in leaf_nodes)\n",
    "\n",
    "    # Build a dictionary of all results/settings\n",
    "    row = {\n",
    "        \"internal_nodes\": internal_str,\n",
    "        \"leaf_nodes\": leaf_str,\n",
    "        \"has_wind\": has_wind,\n",
    "        \"reward_type\": reward_type,\n",
    "        \"is_multiobjective\": is_multiobjective,\n",
    "        \"pop_size\": pop_size,\n",
    "        \"max_gens\": max_gens,\n",
    "        \"best_training\": best_training,\n",
    "        \"best_test\": best_test,\n",
    "        \"average_fitness\": average_fitness,\n",
    "        \"time_elapsed\": time_elapsed,\n",
    "        \"num_evals\": num_evals\n",
    "    }\n",
    "\n",
    "    name = \"multiobjective_improvement.csv\"\n",
    "    if has_wind:\n",
    "        name = \"multiobjective_improvement.csv\"\n",
    "\n",
    "    os.makedirs(\"improvement_results\", exist_ok=True)\n",
    "    filename = os.path.join(\"improvement_results\", name)\n",
    "    \n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=list(row.keys()))\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "def multiobjective_exp(max_gens=30, has_wind=False, is_multiobjective=True):\n",
    "    reward_type = 'avg'\n",
    "    fitness_function_version = make_fitness_function_pt(reduction=reward_type, has_wind=has_wind)\n",
    "    print(f\"\\nRunning experiment multi-objective case: {is_multiobjective}\")\n",
    "    best_training, best_test, average_fitness, average_fitness_test, \\\n",
    "        time_elapsed, num_evals = main_experimentation_loop(fitness_function_version,\n",
    "                                                            internal_nodes, \n",
    "                                                            leaf_nodes,\n",
    "                                                            pop_size=16,\n",
    "                                                            max_gens=max_gens, \n",
    "                                                            max_tree_size=31,\n",
    "                                                            is_multiobjective=is_multiobjective)\n",
    "    print(f\"Best training fitness: {best_training}, Best test fitness: {best_test}, Average fitness: {average_fitness}, Average test fitness: {average_fitness_test}, Time elapsed: {time_elapsed}, Number of evaluations: {num_evals}\")\n",
    "    write_results_to_csv_multiobjective(\n",
    "        internal_nodes=internal_nodes,\n",
    "        leaf_nodes=leaf_nodes,\n",
    "        has_wind=has_wind,\n",
    "        reward_type=reward_type,\n",
    "        is_multiobjective=is_multiobjective,\n",
    "        pop_size=16,\n",
    "        max_gens=max_gens,\n",
    "        best_training=best_training,\n",
    "        best_test=best_test,\n",
    "        average_fitness=average_fitness,\n",
    "        time_elapsed=time_elapsed,\n",
    "        num_evals=num_evals\n",
    "    )\n",
    "\n",
    "multiobjective_exp(max_gens=10, has_wind=False, is_multiobjective=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an animation\n",
    "Here the best evolved individual is selected and one episode is rendered. Make sure to save your lunar landers over time to track progress and make comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "# gist to save gif from https://gist.github.com/botforge/64cbb71780e6208172bbf03cd9293553\n",
    "def save_frames_as_gif(frames, path='./', filename='evolved_lander.gif'):\n",
    "  plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "  patch = plt.imshow(frames[0])\n",
    "  plt.axis('off')\n",
    "  def animate(i):\n",
    "      patch.set_data(frames[i])\n",
    "  anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "  anim.save(path + filename, writer='imagemagick', fps=60)\n",
    "\n",
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "The coefficients in the multi-tree aren't optimised. Here Q-learning (taken from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) is used to optimise the weights further. Incorporate coefficient optimisation in training your agent(s). Coefficient Optimisation can be expensive. Think about how often you want to optimise, when, which individuals etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "GAMMA = 0.99\n",
    "\n",
    "constants = best.get_subtrees_consts()\n",
    "\n",
    "if len(constants)>0:\n",
    "  optimizer = optim.AdamW(constants, lr=1e-3, amsgrad=True)\n",
    "\n",
    "for _ in range(500):\n",
    "\n",
    "  if len(constants)>0 and len(evo.memory)>batch_size:\n",
    "    target_tree = copy.deepcopy(best)\n",
    "\n",
    "    transitions = evo.memory.sample(batch_size)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                        batch.next_state)), dtype=torch.bool)\n",
    "\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                               if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = best.get_output_pt(state_batch).gather(1, action_batch)\n",
    "    next_state_values = torch.zeros(batch_size, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "      next_state_values[non_final_mask] = target_tree.get_output_pt(non_final_next_states).max(1)[0].float()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "   \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(constants, 100)\n",
    "    optimizer.step()\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames, filename='evolved_lander_RL.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander_RL.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.656655013Z",
     "start_time": "2025-06-02T20:49:04.845533Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('hyperparameter_tuning_results/resultscombined')\n",
    "\n",
    "\n",
    "parameters = ['crossover_rate', 'mutation_rate', 'coeff_opt_rate', 'tournament_size']\n",
    "\n",
    "# little wonky conversion to take the last float because the array looks like \"[np.float64(-134359.23), np.float64(-213.35), ...\n",
    "df['average_fitness'] = df['average_fitness'].apply(lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3]))\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, param in enumerate(parameters):\n",
    "    ax = axes[i]\n",
    "    df.boxplot(column='average_fitness', by=param, ax=ax)\n",
    "    # ax.scatter(df[param], df['average_fitness'], alpha=0.5)\n",
    "    ax.set_xlabel(param)\n",
    "    ax.set_ylabel('average_fitness')\n",
    "    ax.set_title(f'{param} vs average_fitness')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T12:03:34.657118374Z",
     "start_time": "2025-06-03T07:37:56.075856Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv('hyperparameter_tuning_results/resultscombined')\n",
    "df['best_training'] = df['best_training'].apply(lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3]))\n",
    "df = df[df['tournament_size'] == 8]\n",
    "# Create 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    df,\n",
    "    x='crossover_rate',\n",
    "    y='mutation_rate',\n",
    "    z='coeff_opt_rate',\n",
    "    color='best_training',\n",
    "    color_continuous_scale='Viridis',\n",
    "    opacity=0.8,\n",
    "    title='3D Scatter Plot of Hyperparameters vs Average Fitness',\n",
    "    labels={\n",
    "        'crossover_rate': 'Crossover Rate',\n",
    "        'mutation_rate': 'Mutation Rate',\n",
    "        'coeff_opt_rate': 'Coeff Opt Rate',\n",
    "        'best_training': 'Best Fitness',\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set renderer (if needed)\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'  # Try 'iframe_connected' or 'browser' if this doesn't show\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Heatmap with One Facet: Coeff Opt Rate \n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('hyperparameter_tuning_results/resultscombined')\n",
    "df['best_training'] = df['best_training'].apply(lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3]))\n",
    "df = df[df['tournament_size'] == 8]\n",
    "\n",
    "# Round to avoid floating point noise in axes\n",
    "df['crossover_rate'] = df['crossover_rate'].round(3)\n",
    "df['mutation_rate'] = df['mutation_rate'].round(3)\n",
    "df['coeff_opt_rate'] = df['coeff_opt_rate'].round(3)\n",
    "\n",
    "# Create faceted heatmaps\n",
    "fig = px.density_heatmap(\n",
    "    df,\n",
    "    x='crossover_rate',\n",
    "    y='mutation_rate',\n",
    "    z='best_training',\n",
    "    facet_col='coeff_opt_rate',\n",
    "    color_continuous_scale='Viridis',\n",
    "    histfunc='avg',\n",
    "    title='Hyperparameter Heatmaps: Fitness vs Crossover & Mutation (Faceted by Coeff Opt Rate)',\n",
    "    labels={\n",
    "        'crossover_rate': 'Crossover Rate',\n",
    "        'mutation_rate': 'Mutation Rate',\n",
    "        'best_training': 'Best Fitness',\n",
    "        'coeff_opt_rate': 'Coeff Opt Rate'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=50, b=20))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Heatmap with Two Facets: Coeff Opt Rate and Tournament Size\n",
    "# This heatmap uses best_fitness metric for selection\n",
    "# and averages this metric across generations\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('hyperparameter_tuning_results/resultscombined')\n",
    "\n",
    "# Extract float value from 'best_training' column\n",
    "df['best_training'] = df['best_training'].apply(lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3]))\n",
    "\n",
    "# Round to avoid floating point noise in axes\n",
    "df['crossover_rate'] = df['crossover_rate'].round(3)\n",
    "df['mutation_rate'] = df['mutation_rate'].round(3)\n",
    "df['coeff_opt_rate'] = df['coeff_opt_rate'].round(3)\n",
    "df['tournament_size'] = df['tournament_size']\n",
    "\n",
    "# Remove configuration where crossover_rate == 1.0\n",
    "df = df[df['crossover_rate'] != 1.0]\n",
    "\n",
    "# Create faceted heatmaps with mutation_rate as row facet and crossover_rate as column facet\n",
    "fig = px.density_heatmap(\n",
    "    df,\n",
    "    x='tournament_size',\n",
    "    y='coeff_opt_rate',\n",
    "    z='best_training',\n",
    "    facet_row='mutation_rate',\n",
    "    facet_col='crossover_rate',\n",
    "    histfunc='avg',\n",
    "    color_continuous_scale='Viridis',\n",
    "    title='Fitness Heatmaps: Tournament Size vs Coeff Opt Rate (Faceted by Mutation & Crossover Rate)',\n",
    "    labels={\n",
    "        'tournament_size': 'Tournament Size',\n",
    "        'coeff_opt_rate': 'Coeff Opt Rate',\n",
    "        'best_training': 'Best Fitness',\n",
    "        'mutation_rate': 'Mutation Rate',\n",
    "        'crossover_rate': 'Crossover Rate'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Improve layout\n",
    "fig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=60, b=20),\n",
    "    height=800,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "# Reduce font size of facet labels to prevent overlap\n",
    "for annotation in fig.layout.annotations:\n",
    "    annotation.font.size = 10\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Heatmap with Two Facets: Coeff Opt Rate and Tournament Size\n",
    "# This heatmap uses avg_fitness metric for selection\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('hyperparameter_tuning_results/resultscombined')\n",
    "\n",
    "# Extract float value from 'average_fitness' column\n",
    "df['average_fitness'] = df['average_fitness'].apply(lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3]))\n",
    "\n",
    "# Round to avoid floating point noise in axes\n",
    "df['crossover_rate'] = df['crossover_rate'].round(3)\n",
    "df['mutation_rate'] = df['mutation_rate'].round(3)\n",
    "df['coeff_opt_rate'] = df['coeff_opt_rate'].round(3)\n",
    "df['tournament_size'] = df['tournament_size']\n",
    "\n",
    "# Create faceted heatmaps with tournament_size as row facet and coeff_opt_rate as column facet\n",
    "fig = px.density_heatmap(\n",
    "    df,\n",
    "    x='crossover_rate',\n",
    "    y='mutation_rate',\n",
    "    z='average_fitness',\n",
    "    facet_row='tournament_size',     # ← Add tournament_size as row facet\n",
    "    facet_col='coeff_opt_rate',      # ← Coeff mutation rate as column facet\n",
    "    histfunc='avg',\n",
    "    color_continuous_scale='Viridis',\n",
    "    title='Fitness Heatmaps: Crossover vs Mutation (Faceted by Coeff Opt Rate and Tournament Size)',\n",
    "    labels={\n",
    "        'crossover_rate': 'Crossover Rate',\n",
    "        'mutation_rate': 'Mutation Rate',\n",
    "        'average_fitness': 'Average Fitness',\n",
    "        'coeff_opt_rate': 'Coeff Opt Rate',\n",
    "        'tournament_size': 'Tournament Size'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Improve layout\n",
    "fig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=60, b=20),\n",
    "    height=800, width=1000\n",
    ")\n",
    "\n",
    "for annotation in fig.layout.annotations:\n",
    "    annotation.font.size = 10\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv('hyperparameter_tuning_results/resultscombined')\n",
    "df['best_training'] = df['best_training'].apply(lambda x: float(x.split(\", \")[-1].split(\"(\")[-1][:-3]))\n",
    "\n",
    "# Filter by tournament_size and a fixed coeff_opt_rate value (adjust if needed)\n",
    "df = df[df['tournament_size'] == 8]\n",
    "df['coeff_opt_rate'] = df['coeff_opt_rate'].round(3)\n",
    "target_coeff = df['coeff_opt_rate'].unique()[0]  # Use first value or set manually\n",
    "df = df[df['coeff_opt_rate'] == target_coeff]\n",
    "\n",
    "# Round to reduce float precision issues\n",
    "df['crossover_rate'] = df['crossover_rate'].round(3)\n",
    "df['mutation_rate'] = df['mutation_rate'].round(3)\n",
    "\n",
    "# Pivot data to create Z-matrix\n",
    "pivot_df = df.pivot_table(\n",
    "    values='best_training',\n",
    "    index='mutation_rate',\n",
    "    columns='crossover_rate',\n",
    "    aggfunc='mean'  # or 'min' depending on your definition of \"best\"\n",
    ")\n",
    "\n",
    "# Extract axes\n",
    "x = pivot_df.columns.values  # crossover_rate\n",
    "y = pivot_df.index.values    # mutation_rate\n",
    "z = pivot_df.values          # best_training\n",
    "\n",
    "# Create 3D surface plot\n",
    "fig = go.Figure(data=[go.Surface(z=z, x=x, y=y, colorscale='Viridis')])\n",
    "fig.update_layout(\n",
    "    title='Average Fitness vs Hyperparameters',\n",
    "    scene=dict(\n",
    "        xaxis_title='Crossover Rate',\n",
    "        yaxis_title='Mutation Rate',\n",
    "        zaxis_title='Average Fitness'\n",
    "    )\n",
    ")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
